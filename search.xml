<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[2019校招-Java多线程面试题总结]]></title>
    <url>%2F2018%2F09%2F10%2Fjava-concurrent-interview%2F</url>
    <content type="text"><![CDATA[总结了 Java 多线程相关的面试题。 1. Object 的 wait()和notify() 方法下图为线程状态的图： Object 对象中的 wait()和notify()是用来实现实现等待 / 通知模式。其中等待状态和阻塞状态是不同的。等待状态的线程可以通过notify() 方法唤醒并继续执行，而阻塞状态的线程则是等待获取新的锁。 调用 wait()方法后，当前线程会进入等待状态，直到其他线程调用notify()或notifyAll() 来唤醒。调用 notify() 方法后，可以唤醒正在等待的单一线程。 2. 并发特性 - 原子性、有序性、可见性原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。可见性：指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。有序性：即程序执行的顺序按照代码的先后顺序执行，不进行指令重排列。 3. synchronized 实现原理？synchronized 可以保证方法或者代码块在运行时，同一时刻只有一个进程可以访问，同时它还可以保证共享变量的内存可见性。 Java 中每一个对象都可以作为锁，这是 synchronized 实现同步的基础： 普通同步方法，锁是当前实例对象 静态同步方法，锁是当前类的 class 对象 同步方法块，锁是括号里面的对象 同步代码块：monitorenter 指令插入到同步代码块的开始位置，monitorexit指令插入到同步代码块的结束位置，JVM 需要保证每一个monitorenter都有一个monitorexit与之相对应。任何对象都有一个 Monitor 与之相关联，当且一个 Monitor 被持有之后，他将处于锁定状态。线程执行到monitorenter 指令时，将会尝试获取对象所对应的 Monitor 所有权，即尝试获取对象的锁。 同步方法：synchronized 方法则会被翻译成普通的方法调用和返回指令如：invokevirtual、areturn指令，在 VM 字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是在 Class 文件的方法表中将该方法的access_flags字段中的synchronized 标志位置设置为 1，表示该方法是同步方法，并使用调用该方法的对象或该方法所属的 Class 在 JVM 的内部对象表示 Klass 作为锁对象。synchronized 是重量级锁，在 JDK1.6 中进行优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 4. volatile 的实现原理？volatile 是轻量级的锁，它不会引起线程上下文的切换和调度。 volatile可见性：对一个volatile 的读，总可以看到对这个变量最终的写。 volatile 原子性：volatile对单个读 / 写具有原子性（32 位 Long、Double），但是复合操作除外，例如i++ 。 JVM 底层采用“内存屏障”来实现 volatile 语义，防止指令重排序。volatile 经常用于两个两个场景：状态标记变量、Double Check 。 5. Java 内存模型（JMM）JMM 规定了线程的工作内存和主内存的交互关系，以及线程之间的可见性和程序的执行顺序。 一方面，要为程序员提供足够强的内存可见性保证。 另一方面，对编译器和处理器的限制要尽可能地放松。JMM 对程序员屏蔽了 CPU 以及 OS 内存的使用问题，能够使程序在不同的 CPU 和 OS 内存上都能够达到预期的效果。Java 采用内存共享的模式来实现线程之间的通信。编译器和处理器可以对程序进行重排序优化处理，但是需要遵守一些规则，不能随意重排序。在并发编程模式中，势必会遇到上面三个概念： 原子性：一个操作或者多个操作要么全部执行要么全部不执行。 可见性：当多个线程同时访问一个共享变量时，如果其中某个线程更改了该共享变量，其他线程应该可以立刻看到这个改变。 有序性：程序的执行要按照代码的先后顺序执行。通过 volatile、synchronized、final、concurrent 包等 实现。 6. 有关队列 AQS 队列同步器AQS 是构建锁或者其他同步组件的基础框架（如 ReentrantLock、ReentrantReadWriteLock、Semaphore 等）, 包含了实现同步器的细节（获取同步状态、FIFO 同步队列）。AQS 的主要使用方式是继承，子类通过继承同步器，并实现它的抽象方法来管理同步状态。 维护一个同步状态 state。当 state 0时，表示已经获取了锁；当state = 0 时，表示释放了锁。 AQS 通过内置的 FIFO 同步队列来完成资源获取线程的排队工作： 如果当前线程获取同步状态失败（锁）时，AQS 则会将当前线程以及等待状态等信息构造成一个节点（Node）并将其加入同步队列，同时会阻塞当前线程 当同步状态释放时，则会把节点中的线程唤醒，使其再次尝试获取同步状态。AQS 内部维护的是 CLH 双向同步队列 7. 锁的特性 可重入锁：指的是在一个线程中可以多次获取同一把锁。 ReentrantLock 和 synchronized 都是可重入锁。 可中断锁：顾名思义，就是可以相应中断的锁。synchronized 就不是可中断锁，而 Lock 是可中断锁。 公平锁：即尽量以请求锁的顺序来获取锁。synchronized 是非公平锁，ReentrantLock 和 ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁。 8. ReentrantLock 锁ReentrantLock，可重入锁，是一种递归无阻塞的同步机制。它可以等同于 synchronized的使用，但是 ReentrantLock 提供了比synchronized 更强大、灵活的锁机制，可以减少死锁发生的概率。 ReentrantLock 实现 Lock 接口，基于内部的 Sync 实现。 Sync 实现 AQS ，提供了 FairSync 和 NonFairSync 两种实现。 Condition Condition 和 Lock 一起使用以实现等待/通知模式，通过 await()和singnal() 来阻塞和唤醒线程。 Condition 是一种广义上的条件队列。他为线程提供了一种更为灵活的等待 / 通知模式，线程在调用 await 方法后执行挂起操作，直到线程等待的某个条件为真时才会被唤醒。Condition 必须要配合 Lock 一起使用，因为对共享状态变量的访问发生在多线程环境下。一个 Condition 的实例必须与一个 Lock 绑定，因此 Condition 一般都是作为 Lock 的内部实现。 9. ReentrantReadWriteLock读写锁维护着一对锁，一个读锁和一个写锁。通过分离读锁和写锁，使得并发性比一般的排他锁有了较大的提升： 在同一时间，可以允许多个读线程同时访问。 但是，在写线程访问时，所有读线程和写线程都会被阻塞。 读写锁的主要特性： 公平性：支持公平性和非公平性。 重入性：支持重入。读写锁最多支持 65535 个递归写入锁和 65535 个递归读取锁。 锁降级：遵循获取写锁，再获取读锁，最后释放写锁的次序，如此写锁能够降级成为读锁。ReentrantReadWriteLock 实现 ReadWriteLock 接口，可重入的读写锁实现类。在同步状态上，为了表示两把锁，将一个 32 位整型分为高 16 位和低 16 位，分别表示读和写的状态 10. Synchronized 和 Lock 的区别 Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言实现； synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock() 去释放锁，则很可能造成死锁现象，因此使用 Lock 时需要在 finally 块中释放锁； Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，等待的线程会一直等待下去，不能够响应中断； 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。 Lock 可以提高多个线程进行读操作的效率。 更深的： 与 synchronized 相比，ReentrantLock 提供了更多，更加全面的功能，具备更强的扩展性。例如：时间锁等候，可中断锁等候，锁投票。 ReentrantLock 还提供了条件 Condition ，对线程的等待、唤醒操作更加详细和灵活，所以在多个条件变量和高度竞争锁的地方，ReentrantLock 更加适合（以后会阐述 Condition）。 ReentrantLock 提供了可轮询的锁请求。它会尝试着去获取锁，如果成功则继续，否则可以等到下次运行时处理，而 synchronized则一旦进入锁请求要么成功要么阻塞，所以相比synchronized 而言，ReentrantLock 会不容易产生死锁些。 ReentrantLock 支持更加灵活的同步代码块，但是使用 synchronized时，只能在同一个synchronized块结构中获取和释放。注意，ReentrantLock 的锁释放一定要在finally 中处理，否则可能会产生严重的后果。 ReentrantLock 支持中断处理，且性能较 synchronized 会好些。 11. Java 中线程同步的方式 sychronized 同步方法或代码块 volatile Lock ThreadLocal 阻塞队列（LinkedBlockingQueue） 使用原子变量（java.util.concurrent.atomic） 变量的不可变性 12. CAS 是一种什么样的同步机制？多线程下为什么不使用 int 而使用 AtomicInteger？Compare And Swap，比较交换。可以看到 synchronized 可以保证代码块原子性，很多时候会引起性能问题，volatile也是个不错的选择，但是volatile 不能保证原子性，只能在某些场合下使用。所以可以通过 CAS 来进行同步，保证原子性。们在读 Concurrent 包下的类的源码时，发现无论是 ReentrantLock 内部的 AQS，还是各种 Atomic 开头的原子类，内部都应用到了 CAS。 在 CAS 中有三个参数：内存值 V、旧的预期值 A、要更新的值 B ，当且仅当内存值 V 的值等于旧的预期值 A 时，才会将内存值 V 的值修改为 B，否则什么都不干。其伪代码如下： 123456if (this.value == A) &#123; this.value = B; return true;&#125; else &#123; return false;&#125; CAS 可以保证一次的读-改-写操作是原子操作。在多线程环境下，int 类型的自增操作不是原子的，线程不安全，可以使用 AtomicInteger 代替。 12345678910// AtomicInteger.javaprivate static final Unsafe unsafe = Unsafe.getUnsafe();private static final long valueOffset;static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField("value")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;private volatile int value; Unsafe 是 CAS 的核心类，Java 无法直接访问底层操作系统，而是通过本地 native` 方法来访问。不过尽管如此，JVM 还是开了一个后门：Unsafe ，它提供了硬件级别的原子操作。 valueOffset 为变量值在内存中的偏移地址，Unsafe 就是通过偏移地址来得到数据的原值的。 value当前值，使用volatile 修饰，保证多线程环境下看见的是同一个。12345678910111213141516// AtomicInteger.javapublic final int addAndGet(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta) + delta;&#125;// Unsafe.java// compareAndSwapInt（var1, var2, var5, var5 + var4）其实换成 compareAndSwapInt（obj, offset, expect, update）比较清楚，意思就是如果 obj 内的 value 和 expect 相等，就证明没有其他线程改变过这个变量，那么就更新它为 update，如果这一步的 CAS 没有成功，那就采用自旋的方式继续进行 CAS 操作，取出乍一看这也是两个步骤了啊，其实在 JNI 里是借助于一个 CPU 指令完成的。所以还是原子操作。public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125;// 该方法为本地方法，有四个参数，分别代表：对象、对象的地址、预期值、修改值public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 13. HashMap 是不是线程安全？如何体现？如何变得安全？由于添加元素到 map 中去时，数据量大产生扩容操作，多线程会导致 HashMap 的 node 链表形成环状的数据结构产生死循环。所以 HashMap 是线程不安全的。如何变得安全： Hashtable：通过 synchronized 来保证线程安全的，独占锁，悲观策略。吞吐量较低，性能较为低下 SynchronizedHashMap ：通过 Collections.synchronizedMap() 方法对 HashMap 进行包装，返回一个 SynchronizedHashMap 对象，在源码中 SynchronizedHashMap 也是用过 synchronized 来保证线程安全的。但是实现方式和 Hashtable 略有不同（前者是 synchronized 方法，后者是通过 synchronized 对互斥变量加锁实现） ConcurrentHashMap：JUC 中的线程安全容器，高效并发。ConcurrentHashMap 的 key、value 都不允许为 null。 14. ConcurrentHashMap 的实现方式？ConcurrentHashMap 的实现方式和 Hashtable 不同，不采用独占锁的形式，更高效，其中在 jdk1.7 和 jdk1.8 中实现的方式也略有不同。 Jdk1.7 中采用分段锁和 HashEntry 使锁更加细化。ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock。不会像 HashTable 那样不管是 put 还是 get 操作都需要做同步处理，理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量）的线程并发。 Jdk1.8 利用 CAS+Synchronized 来保证并发更新的安全，当然底层采用数组+链表+红黑树的存储结构。 table 中存放 Node 节点数据，默认 Node 数据大小为 16，扩容大小总是 2^N。 为了保证可见性，Node 节点中的 val 和 next 节点都用 volatile 修饰。 当链表长度大于 8 时，会转换成红黑树，节点会被包装成 TreeNode放在TreeBin 中。 put()：1. 计算键所对应的 hash 值；2. 如果哈希表还未初始化，调用 initTable() 初始化，否则在 table 中找到 index 位置，并通过 CAS 添加节点。如果链表节点数目超过 8，则将链表转换为红黑树。如果节点总数超过，则进行扩容操作。 get()：无需加锁，直接根据 key 的 hash 值遍历 node。 15. CountDownLatch 和 CyclicBarrier 的区别？ 并发工具类CyclicBarrier 它允许一组线程互相等待，直到到达某个公共屏障点 (Common Barrier Point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 Barrier 在释放等待线程后可以重用，所以称它为循环 ( Cyclic ) 的 屏障 ( Barrier ) 。 每个线程调用 #await() 方法，告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。当所有线程都到达了屏障，结束阻塞，所有线程可继续执行后续逻辑。 CountDownLatch 能够使一个线程在等待另外一些线程完成各自工作之后，再继续执行。使用一个计数器进行实现。计数器初始值为线程的数量。当每一个线程完成自己任务后，计数器的值就会减一。当计数器的值为 0 时，表示所有的线程都已经完成了任务，然后在 CountDownLatch 上等待的线程就可以恢复执行任务。两者区别： CountDownLatch 的作用是允许 1 或 N 个线程等待其他线程完成执行；而 CyclicBarrier 则是允许 N 个线程相互等待。 CountDownLatch 的计数器无法被重置；CyclicBarrier 的计数器可以被重置后使用，因此它被称为是循环的 barrier 。 Semaphore 是一个控制访问多个共享资源的计数器，和 CountDownLatch 一样，其本质上是一个“共享锁”。一个计数信号量。从概念上讲，信号量维护了一个许可集。 如有必要，在许可可用前会阻塞每一个 acquire，然后再获取该许可。 每个 release 添加一个许可，从而可能释放一个正在阻塞的获取者。 16. 什么是乐观锁和悲观锁？像 synchronized这种独占锁属于悲观锁，它是在假设一定会发生冲突的，那么加锁恰好有用，除此之外，还有乐观锁，乐观锁的含义就是假设没有发生冲突，那么我正好可以进行某项操作，如果要是发生冲突呢，那我就重试直到成功，乐观锁最常见的就是CAS。 17. 阻塞队列阻塞队列实现了 BlockingQueue 接口，并且有多组处理方法。抛出异常：add(e) 、remove()、element()返回特殊值：offer(e) 、pool()、peek()阻塞：put(e) 、take()JDK 8 中提供了七个阻塞队列可供使用： ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。 LinkedBlockingQueue ：一个由链表结构组成的无界阻塞队列。 PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。 DelayQueue：一个使用优先级队列实现的无界阻塞队列。 SynchronousQueue：一个不存储元素的阻塞队列。 LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。 LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。 ArrayBlockingQueue，一个由数组实现的有界阻塞队列。该队列采用 FIFO 的原则对元素进行排序添加的。内部使用可重入锁 ReentrantLock + Condition 来完成多线程环境的并发操作。 18. 线程池线程池有五种状态：RUNNING, SHUTDOWN, STOP, TIDYING, TERMINATED。 RUNNING：接收并处理任务。 SHUTDOWN：不接收但处理现有任务。 STOP：不接收也不处理任务，同时终端当前处理的任务。 TIDYING：所有任务终止，线程池会变为 TIDYING 状态。当线程池变为 TIDYING 状态时，会执行钩子函数 terminated()。 TERMINATED：线程池彻底终止的状态。内部变量 ctl 定义为 AtomicInteger ，记录了“线程池中的任务数量”和“线程池的状态”两个信息。共 32 位，其中高 3 位表示”线程池状态”，低 29 位表示”线程池中的任务数量”。 线程池创建参数 corePoolSize 线程池中核心线程的数量。当提交一个任务时，线程池会新建一个线程来执行任务，直到当前线程数等于 corePoolSize。如果调用了线程池的 prestartAllCoreThreads() 方法，线程池会提前创建并启动所有基本线程。maximumPoolSize线程池中允许的最大线程数。线程池的阻塞队列满了之后，如果还有任务提交，如果当前的线程数小于 maximumPoolSize，则会新建线程来执行任务。注意，如果使用的是无界队列，该参数也就没有什么效果了。keepAliveTime线程空闲的时间。线程的创建和销毁是需要代价的。线程执行完任务后不会立即销毁，而是继续存活一段时间：keepAliveTime。默认情况下，该参数只有在线程数大于 corePoolSize 时才会生效。unitkeepAliveTime 的单位。TimeUnitworkQueue用来保存等待执行的任务的阻塞队列，等待的任务必须实现 Runnable 接口。我们可以选择如下几种： ArrayBlockingQueue：基于数组结构的有界阻塞队列，FIFO。 LinkedBlockingQueue：基于链表结构的有界阻塞队列，FIFO。 SynchronousQueue：不存储元素的阻塞队列，每个插入操作都必须等待一个移出操作，反之亦然。 PriorityBlockingQueue：具有优先界别的阻塞队列。 threadFactory用于设置创建线程的工厂。该对象可以通过 Executors.defaultThreadFactory()。他是通过 newThread() 方法提供创建线程的功能，newThread() 方法创建的线程都是“非守护线程”而且“线程优先级都是 Thread.NORM_PRIORITY”。 handlerRejectedExecutionHandler，线程池的拒绝策略。所谓拒绝策略，是指将任务添加到线程池中时，线程池拒绝该任务所采取的相应策略。当向线程池中提交任务时，如果此时线程池中的线程已经饱和了，而且阻塞队列也已经满了，则线程池会选择一种拒绝策略来处理该任务。线程池提供了四种拒绝策略： AbortPolicy：直接抛出异常，默认策略； CallerRunsPolicy：用调用者所在的线程来执行任务； DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务； DiscardPolicy：直接丢弃任务； 当然我们也可以实现自己的拒绝策略，例如记录日志等等，实现 RejectedExecutionHandler 接口即可。当添加新的任务到线程池时： 线程数量未达到 corePoolSize，则新建一个线程（核心线程）执行任务 线程数量达到了 corePoolSize，则将任务移入队列等待 队列已满，新建线程（非核心线程）执行任务 队列已满，总线程数又达到了 maximumPoolSize，就会由 handler 的拒绝策略来处理 线程池可通过 Executor 框架来进行创建： FixedThreadPool12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; corePoolSize 和 maximumPoolSize 都设置为创建 FixedThreadPool 时指定的参数 nThreads，意味着当线程池满时且阻塞队列也已经满时，如果继续提交任务，则会直接走拒绝策略，该线程池不会再新建线程来执行任务，而是直接走拒绝策略。FixedThreadPool 使用的是默认的拒绝策略，即 AbortPolicy，则直接抛出异常。 但是 workQueue 使用了无界的 LinkedBlockingQueue, 那么当任务数量超过 corePoolSize 后，全都会添加到队列中而不执行拒绝策略。 SingleThreadExecutor123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 作为单一 worker 线程的线程池，SingleThreadExecutor 把 corePool 和 maximumPoolSize 均被设置为 1，和 FixedThreadPool 一样使用的是无界队列 LinkedBlockingQueue, 所以带来的影响和 FixedThreadPool 一样。 CachedThreadPool CachedThreadPool是一个会根据需要创建新线程的线程池 ，他定义如下：12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 这个线程池，当任务提交是就会创建线程去执行,执行完成后线程会空闲60s,之后就会销毁。但是如果主线程提交任务的速度远远大于 CachedThreadPool 的处理速度，则 CachedThreadPool 会不断地创建新线程来执行任务，这样有可能会导致系统耗尽 CPU 和内存资源，所以在使用该线程池是，一定要注意控制并发的任务数，否则创建大量的线程可能导致严重的性能问题。 19. 为什么要使用线程池？ 创建/销毁线程伴随着系统开销，过于频繁的创建/销毁线程，会很大程度上影响处理效率。线程池缓存线程，可用已有的闲置线程来执行新任务(keepAliveTime) 线程并发数量过多，抢占系统资源从而导致阻塞。运用线程池能有效的控制线程最大并发数，避免以上的问题。 对线程进行一些简单的管理(延时执行、定时循环执行的策略等) 20. 生产者消费者问题实例代码用 Object 的 wait()和notify() 实现，也可用 ReentrantLock 和 Condition 来完成。或者直接使用阻塞队列。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class ProducerConsumer &#123; public static void main(String[] args) &#123; ProducerConsumer main = new ProducerConsumer(); Queue&lt;Integerbuffer = new LinkedList&lt;&gt;(); int maxSize = 5; new Thread(main.new Producer(buffer, maxSize), "Producer1").start(); new Thread(main.new Consumer(buffer, maxSize), "Comsumer1").start(); new Thread(main.new Consumer(buffer, maxSize), "Comsumer2").start(); &#125; class Producer implements Runnable &#123; private Queue&lt;Integerqueue; private int maxSize; Producer(Queue&lt;Integerqueue, int maxSize) &#123; this.queue = queue; this.maxSize = maxSize; &#125; @Override public void run() &#123; while (true) &#123; synchronized (queue) &#123; while (queue.size() == maxSize) &#123; try &#123; System.out.println("Queue is full"); queue.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; Random random = new Random(); int i = random.nextInt(); System.out.println(Thread.currentThread().getName() + " Producing value : " + i); queue.add(i); queue.notifyAll(); &#125; &#125; &#125; &#125; class Consumer implements Runnable &#123; private Queue&lt;Integerqueue; private int maxSize; public Consumer(Queue&lt;Integerqueue, int maxSize) &#123; super(); this.queue = queue; this.maxSize = maxSize; &#125; @Override public void run() &#123; while (true) &#123; synchronized (queue) &#123; while (queue.isEmpty()) &#123; try &#123; System.out.println("Queue is empty"); queue.wait(); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + " Consuming value : " + queue.remove()); queue.notifyAll(); &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>技术杂记</category>
      </categories>
      <tags>
        <tag>Concurrent</tag>
        <tag>Java</tag>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[译]Kubernetes 分布式应用部署和人脸识别 app 实例]]></title>
    <url>%2F2018%2F06%2F23%2Fkubernetes-distributed-application%2F</url>
    <content type="text"><![CDATA[原文地址：KUBERNETES DISTRIBUTED APPLICATION DEPLOYMENT WITH SAMPLE FACE RECOGNITION APP 原文作者：skarlso 译文出自：掘金翻译计划 好的，伙计，让我们静下心来。下面将会是一个漫长但充满希望和有趣的旅程。 我将使用 Kubernetes 部署分布式应用程序。我试图创建一个类似于真实世界 app 的应用程序。显然，由于时间和精力有限，我不得不忽略一些细节部分。 我的重点将放在 Kubernetes 和应用部署上。 准备好进入正题了吗？ 关于应用摘要 应用程序由六个部分组成。代码仓库可在这里找到：Kube Cluster Sample。 这是一个人脸识别的服务应用，它可以识别人物的图像并将其和已知人物进行比较。识别结果会在一个简单的前端中，通过表格的形式展现出来，可以看到这些待识别的图像中的人物是谁。应用的运行过程如下：首先向接收器发送请求，请求中需要包含图像的路径。这些图像可存储在 NFS 一类的地方，同时接收器会将图像路径存储在 DB（MySQL）中。最后向队列发送一个处理请求，包含保存图像的 ID。这里使用 NSQ 作为队列（译者注：NSQ 是一个基于 Go 语言的分布式实时消息平台）。 期间，图像处理服务会不间断地监视将要执行作业的队列。处理流程由以下步骤组成：取 ID；加载图像；最后，通过 gRPC 将图像发送到用 Python 编写的人脸识别后端程序。如果识别成功，后端将返回与该图像中人物相对应的名称。然后，图像处理器会更新图像记录的人物 ID 字段，并将图像标记为“processed successfully”。如果识别不成功，图像将被保留为“pending”。 如果在识别过程中出现故障，图像将被标记为“failed”。 处理失败的图像可以通过 cron 作业重试，例如： 那么这是如何工作的？让我们来看看 。 接收器接收器服务是整个流程的起点。这个 API 接收如下格式的请求： 1curl -d &apos;&#123;&quot;path&quot;:&quot;/unknown_images/unknown0001.jpg&quot;&#125;&apos; http://127.0.0.1:8000/image/post 在这个例子中，接收器通过共享数据库集群来存储图像路径。当数据库存储图像路径成功后，接收器实例就能从数据库服务中接收图像 ID。此应用程序是基于在持久层提供实体对象唯一标识的模型的。一旦 ID 产生，接收器会向 NSQ 发送一个消息。到这里，接收器的工作就完成了。 图像处理器下面是激动人心的开始。当图像处理器第一次运行时，它会创建两个 Go 协程（routine）。 他们是： Consume这是一个 NSQ 消费者。它有三个必要的工作。首先，它能够监听队列中的消息。其次，当其接收到消息后，会将收到的 ID 添加到第二个例程处理的线程安全的 ID 切片中去。最后，它通过 sync.Condition 告知第二个协程有工作要做。 ProcessImages该例程处理 ID 切片，直到切片完全耗尽。一旦切片消耗完，例程将暂停而不是等待 channel。以下是处理单个 ID 的步骤： 与人脸识别服务建立 gRPC 连接（在下面人脸识别章节解释） 从数据库中取回图像记录 设置 断路器 的两个函数 函数 1: 运行 RPC 方法调用的主函数 函数 2: 对断路器的 Ping 进行健康检查 调用函数 1，发送图像路径到人脸识别服务。服务需要能够访问该路径。最好能像 NFS 一样进行文件共享 如果调用失败，更新图像记录的状态字段为“FAILED PROCESSING” 如果成功，将会返回数据库中与图片相关的人物名。它会执行一个 SQL 的连接查询，获取到相关的人物 ID 更新数据库中图片记录的状态字段为“PROCESSED”，以及人物字段为识别出的人物 ID 这个服务可以被复制，换句话说，可以同时运行多个服务。 断路器虽然这是一个不需要太大精力就能够复制资源的系统，但仍可能存在状况，例如网络故障、服务间的通信问题。因此我在 gRRC 调用上实现了一个小小的断路器作为乐趣。 它是这样工作的： 正如你所见到的，在服务中一旦有 5 个不成功的调用，断路器将会被激活，并且不允许任何调用通过。经过一段配置的时间后，会向服务发送一个 Ping 调用，并检测服务是否返回信息。如果仍然出错，会增加超时时间，否则就会打开，允许流量通过。 前端这只是一个简单的表格视图，使用 Go 自带的 HTML 模板来渲染图像列表。 人脸识别这里是识别魔术发生的地方。为了追求灵活性，我决定将人脸识别这项功能封装成为基于 gRPC 的服务。我开始打算用 Go 语言去编写，但后来发现使用 Python 来实现会更加清晰。事实上，除了 gPRC 代码之外，人脸识别部分大概需要 7 行 Python 代码。我正在使用一个极好的库，它包含了所有 C 实现的 OpenCV 的调用。人脸识别。在这里签订 API 使用协议，也就意味着在协议的许可下，我可以随时更改人脸识别代码的实现。 请注意，这里存在一个可以用 Go 语言来开发 OpenCV 的库。我差点就用它了，但是它并没有包含 C 实现的 OpenCV 的调用。这个库叫做 GoCV，你可以去了解一下。它们有些非常了不起的地方，比如，实时的摄像头反馈处理，只需要几行代码就能够实现。 python 的库本质上很简单。现在，我们有一组已知的人物图像，并将其命名为 hannibal_1.jpg, hannibal_2.jpg, gergely_1.jpg, john_doe.jpg 放在文件夹中。在数据库中包含两张表，分别是 person 和 person_images。它们看起来像这样： 12345678910111213+----+----------+| id | name |+----+----------+| 1 | Gergely || 2 | John Doe || 3 | Hannibal |+----+----------++----+----------------+-----------+| id | image_name | person_id |+----+----------------+-----------+| 1 | hannibal_1.jpg | 3 || 2 | hannibal_2.jpg | 3 |+----+----------------+-----------+ 脸部识别库返回来自已知人物的图像的名称，其与未知图像中的人物匹配。之后，一个简单的连接查询，就像这样，会返回识别出的人物信息。 1select person.name, person.id from person inner join person_images as pi on person.id = pi.person_id where image_name = &apos;hannibal_2.jpg&apos;; gRPC 调用会返回人物的 ID，并用于修改待识别图像记录中 person 那一列的值。 NSQNSQ 是一个极好的基于 Go 语言的队列。它可伸缩并且在系统上具有最小的占用空间。它还具有消费者用来接收消息的查找服务，以及发送者在发送消息时使用的守护程序。 NSQ 的理念是守护进程应该与发送者应用程序一起运行。这样，发件人只会发送到本地主机。但守护进程连接到查找服务，他们就是这样实现全局队列。 这就意味着，有多少个发送者，有需要部署多少个 NSQ 守护进程。由于守护进程的资源要求很小，不会影响主应用程序的需求。 配置为了尽可能灵活，以及使用 Kubernetes 的 ConfigSet，我在开发中使用 .env 文件来存储配置，如数据库服务的位置或 NSQ 的查找地址。 在生产中，这意味着在 Kubernetes 环境中，我将使用环境变量。 人脸识别应用程序总结这就是我们即将部署的应用程序的架构。它的所有组件都是可变的，只能通过数据库，队列和 gRPC 进行耦合。由于更新机制的工作原因，这在部署分布式应用程序时非常重要。我将在“部署”部分中介绍该部分。 在 Kubernetes 中部署应用基础什么是 Kubernetes？ 我将在这里介绍一些基础知识，但不会过多介绍细节。如果你想了解更多，可阅读的整本书：Kubernetes Up And Running。另外，如果你足够大胆，你可以看看这个文档：Kubernetes Documentation。 Kubernetes 是一个容器化的服务和应用程序管理平台。它容易扩展，可管理一大堆容器，最重要的是，它可以通过基于 yaml 的模板文件高度配置。人们经常将 Kubernetes 与Docker 集群进行比较，但 Kubernetes 确实不止于此！例如：它可以管理不同的容器。你可以使用 Kubernetes 来对LXC 进行管理和编排，同时也可以使用相同的方式管理 Docker。它提供了一个高于管理已部署服务和应用程序集群的层。怎么样？让我们快速浏览一下 Kubernetes 的构建模块吧。 在 Kubernetes 中，您将描述应用程序的期望状态，Kubernetes 会做一些事情，使之达到这个状态。状态可能是部署、暂停、重复两次等等。 Kubernetes 的基础知识之一是它为所有组件使用标签和注解。Services，Deployments，ReplicaSets，DaemonSets，一切都能够被标记。考虑以下情况。为了确定哪个 pod 属于哪个应用程序，我们将会使用了一个名为 app：myapp 的标签。假设您已部署了此应用程序的两个容器; 如果您从其中一个容器中移除标签 app，则 Kubernetes 只会检测到一个标签，因此会启动一个新的 myapp 实例。 Kubernetes Cluster对于 Kuberenetes 的工作，需要有 Kubernetes 集群的存在。配置集群可能是非常痛苦的，但幸运的是，帮助就在眼前。Minikube 在本地为我们配置一个带有一个节点的集群。AWS 有一个以 Kubernetes 集群形式运行的测试服务，其中您唯一需要做的就是请求节点并定义你的部署。Kubernetes 集群组件的文档在此处：Kubernetes Cluster Components。 Nodes一个节点就是一台工作主机。它可以是任何事物，例如物理机、虚拟机以及各种云服务提供的虚拟资源。 PodsPods 是一个逻辑上分组的容器，也就意味着一个 Pod 可以容纳多个容器。一个 Pod 在创建后会获得自己的 DNS 和虚拟 IP 地址，这样Kubernetes 就可以为其平衡流量。你很少需要直接处理容器，即使在调试时（比如查看日志），通常也会调用 kubectl logs deployment / your-app -f 而不是查看特定的容器。尽管有可能会调用 -c container_name。 -f 参数会持续显示日志文件的末尾部分。 Deployments在 Kubernetes 中创建任何类型的资源时，它将在后台使用 Deployment。一个 Deployment 对象描述当前应用程序的期望状态。这东西可以用来变换 Pod 或 Service 的状态，更新或推出新版的应用。您不直接控制 ReplicaSet（如稍后所述），但可以控制 Deployment 对象来创建和管理 ReplicaSet。 Services默认情况下，Pod 会得到一个 IP 地址。然而，因为 Pods 在 Kubernetes 中是一个不稳定的东西，所以你需要更持久的东西。队列、mysql、内部API、前端，这些需要长时间运行并且需要在一个静态的，不变的IP或最好是 DNS 记录之后。 为此，Kubernetes 提供可定义可访问模式的 Services。负载均衡，简单 IP 或内部 DNS。 Kubernetes 如何知道服务是否正确运行？你可以配置运行状况检查和可用性检查。运行状况检查将检查容器是否正在运行，但这并不意味着你的服务正在运行。为此，你需要在您的应用程序中对可用的端点进行可用性检查。 由于 Services 非常重要，我建议你稍后在这里阅读它们：Services。预先提醒，这部分文档内容很多，有 24 个 A4 大小的页面，内容包含网络、服务和发现。但是这对于你是否决定要在生产环境中使用 Kubernetes 是至关重要的。 DNS / Service Discovery如果您在集群中创建服务，该服务将获取由特殊的Kubernetes Deployments 对象（被称作为 kube-proxy 和 kube-dns）提供的在 Kubernetes 中的 DNS 记录。这两个对象在集群中提供了服务发现。如果您运行了mysql服务并设置了 clusterIP：none，那么集群中的每个人都可以通过 ping mysql.default.svc.cluster.local 来访问该服务。 其中： mysql – 服务的名称 default – 命名空间名称 svc – 服务本身 cluster.local – 本地集群域名 该域名可以通过自定义来更改。要访问集群外部的服务，必须有 DNS 提供者，再使用Nginx（例如）将IP地址绑定到记录。可以使用以下命令查询服务的公共IP地址： NodePort – kubectl get -o jsonpath=&quot;{.spec.ports[0].nodePort}&quot; services mysql LoadBalancer – kubectl get -o jsonpath=&quot;{.spec.ports[0].LoadBalancer}&quot; services mysql Template Files像 Docker Compose、TerraForm 或其他服务管理工具一样，Kubernetes 也提供了配置模板的基础设施。这意味着你很少需要手工做任何事情。 例如，请看下面使用 yaml 文件来配置 nginx 部署的模板： 123456789101112131415161718192021apiVersion: apps/v1kind: Deployment #(1)metadata: #(2) name: nginx-deployment labels: #(3) app: nginxspec: #(4) replicas: 3 #(5) selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: #(6) - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 在这个简单的部署中，我们做了以下工作： (1) 使用 kind 属性定义模板的类型 (2) 添加可识别此部署的元数据以及使用 label 创建每一个资源 (3) (4) 然后描述所需要的状态规格。 (5) 对于 nginx 应用程序，包含 3 个 replicas (6) 这是关于容器的模板定义。这里配置的 Pod 包含一个 name 为 nginx 的容器。其中，使用 1.7.9 版本的 nginx 镜像（这个例子中使用的是 Docker），暴露的端口号为：80 ReplicaSetReplicaSet 是低级复制管理器。 它确保为应用程序运行正确数量的复制。 但是，当部署处于较高级别，应始终管理 ReplicaSets。你很少需要直接使用 ReplicaSets，除非您有一个需要控制复制细节的特殊案例。 DaemonSet还记得我说的Kubernetes是如何持续使用标签的吗？DaemonSet 是一个控制器，用于确保守护程序应用程序始终在具有特定标签的节点上运行。 例如：您希望所有标有 logger 或 mission_critical 的节点运行记录器/审计服务守护程序。然后你创建一个 DaemonSet，并给它一个名为 logger 或 mission_critical 的节点选择器。Kubernetes 将寻找具有该标签的节点。始终确保它将有一个守护进程的实例在其上运行。因此，在该节点上运行的每个实例都可以在本地访问该守护进程。 在我的应用程序中，NSQ 守护进程可能是一个 DaemonSet。为了确保它在具有接收器组件的节点上运行，我采用 receiver 标记一个节点，并用 receiver 应用程序选择器指定一个 DaemonSet。 DaemonSet 具有 ReplicaSet 的所有优点。它是可扩展的并由Kubernetes管理它。这意味着，所有的生命周期事件都由 Kube 处理，确保它永不消亡，并且一旦发生，它将立即被替换。 Scaling在 Kubernetes 中做扩展很简单。ReplicaSets 负责管理 Pod 的实例数量，如 nginx 部署中所看到的，使用“replicas：3”设置。我们应该以允许 Kubernetes 运行它的多个副本的方式编写我们的应用程序。 当然这些设置是巨大的。你可以指定哪些复制必须在什么节点上运行，或者在各种等待时间等待实例出现的时间。你可以在这里阅读关于此主题的更多信息：Horizontal Scaling 和此处：Interactive Scaling with Kubernetes，当然还有一个 ReplicaSet 控件的详细信息 所有的 scaling 都可以在 Kubernetes 中实现。 Kubernetes 总结这是一个处理容器编排的便利工具。 它的基本单位是具有分层的架构的 Pods。顶层是 Deployments，通过它处理所有其他资源。它高度可配置，提供了一个用于所有调用的 API，因此比起运行 kubectl，你可以编写自己的逻辑将信息发送到 Kubernetes API。 Kubernetes 现在支持所有主要的云提供商，它完全是开源的，随意贡献！如果你想深入了解它的工作方式，请查看代码：Kubernetes on Github。 Minikube我将使用 Minikube。Minikube 是一个本地 Kubernetes 集群模拟器。尽管模拟多个节点并不是很好，但如果只是着手去学习并在本地折腾一下的话，这种方式不需要任何的开销，是极好的。Minikube是基于虚拟机的，如果需要的话，可以使用 VirtualBox 等进行微调。 所有我将要使用的 kube 模板文件可以在这里找到：Kube files。 注意：如果稍后想要使用 scaling 但注意到复制总是处于“Pending”状态，请记住 minikube 仅使用单个节点。它可能不允许同一节点上有多个副本，或者只是明显耗尽了资源。您可以使用以下命令检查可用资源： 1kubectl get nodes -o yaml 创建容器Kubernetes 支持大部分容器。我将要使用 Docker。对于我构建的所有服务，存储库中都包含一个 Dockerfile。我鼓励你去研究它们。他们大多数都很简单。对于 Go 服务，我正在使用最近引入的多阶段构建。Go 服务是基于 Alpine Linux 的。人脸识别服务是 Python实现的。NSQ 和 MySQL 正在使用他们自己的容器。 上下文Kubernetes 使用命名空间。如果你没有指定任何命名空间，它将使用 default 命名空间。我将永久设置一个上下文以避免污染默认命名空间。 你可以这样做： 12❯ kubectl config set-context kube-face-cluster --namespace=faceContext &quot;kube-face-cluster&quot; created. 一旦它创建完毕，你也必须开始使用上下文，如下所示： 12❯ kubectl config use-context kube-face-clusterSwitched to context &quot;kube-face-cluster&quot;. 在此之后，所有 kubectl 命令将使用命名空间 face。 部署应用Pods 和 Services 概述： MySQL我要部署的第一个 Service 是我的数据库。 我正在使用位于此处的 Kubernetes 示例 Kube MySQL，它符合我的需求。请注意，该配置文件正在使用明文密码。我将按照此处所述 Kubernetes Secrets做一些安全措施。 如文档中描述的那样，我使用保密的 yaml 在本地创建了一个秘钥文件。 1234567apiVersion: v1kind: Secretmetadata: name: kube-face-secrettype: Opaquedata: mysql_password: base64codehere 我通过以下命令创建了base64代码： 1echo -n &quot;ubersecurepassword&quot; | base64 这是您将在我的部署yaml文件中看到的内容： 1234567...- name: MYSQL_ROOT_PASSWORD valueFrom: secretKeyRef: name: kube-face-secret key: mysql_password... 另外值得一提的是：它使用一个 volume 来保存数据库。volume 定义如下： 12345678910... volumeMounts: - name: mysql-persistent-storage mountPath: /var/lib/mysql... volumes: - name: mysql-persistent-storage persistentVolumeClaim: claimName: mysql-pv-claim... presistentVolumeClain 在这里是关键。这告诉 Kubernetes 这个资源需要一个持久的 volume。如何提供它是从用户抽象出来的。你可以确定 Kubernetes 将提供 volume。它与 Pods 类似。要阅读详细信息，请查看此文档：Kubernetes Persistent Volumes。 使用以下命令完成部署 mysql 服务： 1kubectl apply -f mysql.yaml apply 还是 create？简而言之，apply 被认为是声明性的对象配置命令，而 create 则是命令式的。这意味着现在“create”通常是针对其中一项任务的，比如运行某些东西或创建 Deployment。而在使用 apply 时，用户不会定义要采取的操作。这将由 Kubernetes 根据集群的当前状态进行定义。因此，当没有名为 mysql 的服务时，我调用 apply -f mysql.yaml，它会创建服务。再次运行时，Kubernetes 不会做任何事情。但是，如果我再次运行 create，它会抛出一个错误，说明服务已经被创建。 有关更多信息，请查看以下文档：Kubernetes Object Management，Imperative Configuration，Declarative Configuration）。 要查看进度信息，请运行： 1234# 描述整个进程kubectl describe deployment mysql# 仅显示 podkubectl get pods -l app=mysql 输出应该与此类似： 12345678... Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailableOldReplicaSets: &lt;none&gt;NewReplicaSet: mysql-55cd6b9f47 (1/1 replicas created)... 或者在 get pods 的情况下: 12NAME READY STATUS RESTARTS AGEmysql-78dbbd9c49-k6sdv 1/1 Running 0 18s 要测试实例，请运行以下代码片段： 1kubectl run -it --rm --image=mysql:5.6 --restart=Never mysql-client -- mysql -h mysql -pyourpasswordhere 需要了解的是 ：如果你现在更改密码，重新应用 yaml 文件更新容器是不够的。由于数据库持续存在，因此密码将不会更改 你必须使用 kubectl delete -f mysql.yaml 删除整个部署。 运行 show databases 时应该看到以下内容。 12345678910111213141516If you don&apos;t see a command prompt, try pressing enter.mysql&gt;mysql&gt;mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || kube || mysql || performance_schema |+--------------------+4 rows in set (0.00 sec)mysql&gt; exitBye 你还会注意到我已经在这里安装了一个文件：Database Setup SQL到容器中。MySQL 容器自动执行这些。该文件将初始化一些数据以及我将要使用的模式。 volume 定义如下： 12345678910111213 volumeMounts: - name: mysql-persistent-storage mountPath: /var/lib/mysql - name: bootstrap-script mountPath: /docker-entrypoint-initdb.d/database_setup.sqlvolumes:- name: mysql-persistent-storage persistentVolumeClaim: claimName: mysql-pv-claim- name: bootstrap-script hostPath: path: /Users/hannibal/golang/src/github.com/Skarlso/kube-cluster-sample/database_setup.sql type: File 要检查引导脚本是否成功，请运行以下命令： 123456789101112131415~/golang/src/github.com/Skarlso/kube-cluster-sample/kube_files master*❯ kubectl run -it --rm --image=mysql:5.6 --restart=Never mysql-client -- mysql -h mysql -uroot -pyourpasswordhere kubeIf you don&apos;t see a command prompt, try pressing enter.mysql&gt; show tables;+----------------+| Tables_in_kube |+----------------+| images || person || person_images |+----------------+3 rows in set (0.00 sec)mysql&gt; 这结束了数据库服务设置。可以使用以下命令查看该服务的日志： 1kubectl logs deployment/mysql -f NSQ 查找NSQ 查找将作为内部服务运行，它不需要从外部访问。所以我设置了 clusterIP：None，这会告诉 Kubernetes 这项服务是一项无头（headless）的服务。这意味着它不会被负载均衡，并且不会是单一的 IP 服务。DNS 将会基于服务选择器。 我们定义的 NSQ Lookup 选择器是： 123selector:matchLabels: app: nsqlookup 因此，内部 DNS 将如下所示：nsqlookup.default.svc.cluster.local。 无头服务在这里详细描述：Headless Service。 基本上它和 MySQ L一样，只是稍作修改。如前所述，我使用的是 NSQ 自己的 Docker 镜像，名为 nsqio / nsq。所有的 nsq 命令都在那里，所以 nsqd 也将使用这个镜像，只是命令有所不同。对于 nsqlookupd，命令是： 12command: [&quot;/nsqlookupd&quot;]args: [&quot;--broadcast-address=nsqlookup.default.svc.cluster.local&quot;] 你可能会问什么是 --broadcast-address？默认情况下，nsqlookup 将使用 hostname 作为广播地址 当消费者运行回调时，它会尝试连接到类似于 http://nsqlookup-234kf-asdf:4161/lookup?topics=image 的 url。请注意 nsqlookup-234kf-asdf 是容器的主机名。通过将广播地址设置为内部 DNS，回调将为：http://nsqlookup.default.svc.cluster.local:4161/lookup?topic=images。这将按预期工作。 NSQ 查找还需要两个端口进行转发：一个用于广播，一个用于 nsqd 回调。这些在 Dockerfile 中公开，然后 在Kubernetes 模板中使用。像这个： 在容器模板中： 12345ports:- containerPort: 4160 hostPort: 4160- containerPort: 4161 hostPort: 4161 在服务模板中： 12345678910spec: ports: - name: tcp protocol: TCP port: 4160 targetPort: 4160 - name: http protocol: TCP port: 4161 targetPort: 4161 name 是 Kubernetes 需要的。 要创建此服务，我使用与以前相同的命令： 1kubectl apply -f nsqlookup.yaml 到这里，有关于 nsqlookupd 的就结束了。 接收器这是一个更复杂的问题。接收器会做三件事情： 创建一些 deployments 创建 nsq 守护进程 向公众提供服务 Deployments它创建的第一个 deployment 对象是它自己的。Receiver的容器是 skarlso / kube-receiver-alpine。 Nsq 守护进程Receiver 启动一个 nsq 守护进程。如前所述，接收者用它自己运行 nsqd。它这样做可以在本地通信而不是通过网络。通过让接收器执行此操作，它们将在同一节点上结束。 NSQ 守护进程还需要一些调整和参数。 123456789101112ports:- containerPort: 4150 hostPort: 4150- containerPort: 4151 hostPort: 4151env:- name: NSQLOOKUP_ADDRESS value: nsqlookup.default.svc.cluster.local- name: NSQ_BROADCAST_ADDRESS value: nsqd.default.svc.cluster.localcommand: [&quot;/nsqd&quot;]args: [&quot;--lookupd-tcp-address=$(NSQLOOKUP_ADDRESS):4160&quot;, &quot;--broadcast-address=$(NSQ_BROADCAST_ADDRESS)&quot;] 你可以看到设置了 lookup-tcp-address 和 broadcast-address 这两个参数。查找 tcp 地址是 nsqlookupd 服务的 DNS。广播地址是必要的，就像 nsqlookupd 一样，所以回调工作正常。 面向大众的服务现在，这是我第一次部署面向公众的服务。这里有两种选择。我可以使用 LoadBalancer，因为这个 API 可以承受很大的负载。如果这将在生产环境部署，那么它应该使用这一个。 我在本地做只部署单个节点的，所以称为“NodePort”就足够了。一个 NodePort 在一个静态端口上暴露每个节点 IP 上的服务。如果未指定，它将在 30000-32767 之间的主机上分配一个随机端口。但它也可以被配置为一个特定的端口，在模板文件中使用 nodePort。要使用此服务，请使用 &lt;NodeIP&gt;：&lt;NodePort&gt;。如果配置了多个节点，则 LoadBalancer 可以将它们复用到单个 IP。 有关更多信息，请查看此文档：Publishing Service。 综合起来，我们会得到一个接收服务，其模板如下： 123456789101112apiVersion: v1kind: Servicemetadata: name: receiver-servicespec: ports: - protocol: TCP port: 8000 targetPort: 8000 selector: app: receiver type: NodePort 对于 8000 上的固定节点端口，必须提供 nodePort 的定义： 12345678910111213apiVersion: v1kind: Servicemetadata: name: receiver-servicespec: ports: - protocol: TCP port: 8000 targetPort: 8000 selector: app: receiver type: NodePort nodePort: 8000 图像处理器图像处理器是我处理传递图像以识别的地方。它应该有权访问 nsqlookupd，mysql 和人脸识别服务的 gRPC 端点。这实际上是相当无聊的服务。事实上，它甚至不是一项服务。它不会公开任何内容，因此它是第一个部署的组件。为简洁起见，以下是整个模板： 1234567891011121314151617181920212223242526272829303132333435---apiVersion: apps/v1kind: Deploymentmetadata: name: image-processor-deploymentspec: selector: matchLabels: app: image-processor replicas: 1 template: metadata: labels: app: image-processor spec: containers: - name: image-processor image: skarlso/kube-processor-alpine:latest env: - name: MYSQL_CONNECTION value: &quot;mysql.default.svc.cluster.local&quot; - name: MYSQL_USERPASSWORD valueFrom: secretKeyRef: name: kube-face-secret key: mysql_userpassword - name: MYSQL_PORT # TIL: 如果这里的 3306 没有引号，kubectl 会出现错误 value: &quot;3306&quot; - name: MYSQL_DBNAME value: kube - name: NSQ_LOOKUP_ADDRESS value: &quot;nsqlookup.default.svc.cluster.local:4161&quot; - name: GRPC_ADDRESS value: &quot;face-recog.default.svc.cluster.local:50051&quot; 这个文件中唯一有趣的地方是用于配置应用程序的大量环境属性。请注意 nsqlookupd 地址和 grpc 地址。 要创建此部署，请运行： 1kubectl apply -f image_processor.yaml 人脸识别人脸识别别服务是一个简单的，只有图像处理器才需要的服务。它的模板如下： 123456789101112apiVersion: v1kind: Servicemetadata: name: face-recogspec: ports: - protocol: TCP port: 50051 targetPort: 50051 selector: app: face-recog clusterIP: None 更有趣的部分是它需要两个 volume。这两 volume 是 known_people 和 unknown_people。你能猜到他们将包含什么吗？是的，图像。“known_people” volume 包含与数据库中已知人员关联的所有图像。unknown_people volume 将包含所有新图像。这就是我们从接收器发送图像时需要使用的路径; 那就是挂载点所指向的地方，在我的情况下是 / unknown_people。 基本上，路径必须是人脸识别服务可以访问的路径。 现在，通过 Kubernetes 和 Docker部署 volume 很容易。它可以是挂载的 S3 或某种类型的 nfs，也可以是从主机到客户机的本地挂载。也会存在其他可能性。为了简单起见，我将使用本地安装。 安装一个 volume 分两部分完成。首先，Dockerfile 必须指定 volume： 1VOLUME [ &quot;/unknown_people&quot;, &quot;/known_people&quot; ] 其次，Kubernetes 模板需要在 MySQL 服务中添加 volumeMounts，不同之处在于 hostPath 并不是声称的 volume： 1234567891011121314volumeMounts:- name: known-people-storage mountPath: /known_people- name: unknown-people-storage mountPath: /unknown_peoplevolumes:- name: known-people-storagehostPath: path: /Users/hannibal/Temp/known_people type: Directory- name: unknown-people-storagehostPath: path: /Users/hannibal/Temp/ type: Directory 我们还需要为人脸识别服务设置 known_people 文件夹配置。这是通过环境变量完成的： 123env:- name: KNOWN_PEOPLE value: &quot;/known_people&quot; 然后 Python 代码将查找图像，如下所示： 123known_people = os.getenv(&apos;KNOWN_PEOPLE&apos;, &apos;known_people&apos;)print(&quot;Known people images location is: %s&quot; % known_people)images = self.image_files_in_folder(known_people) 其中 image_files_in_folder 函数如下： 12def image_files_in_folder(self, folder): return [os.path.join(folder, f) for f in os.listdir(folder) if re.match(r&apos;.*\.(jpg|jpeg|png)&apos;, f, flags=re.I)] Neat. 现在，如果接收方收到一个请求（并将其发送到更远的线路），与下面的请求类似。 1curl -d &apos;&#123;&quot;path&quot;:&quot;/unknown_people/unknown220.jpg&quot;&#125;&apos; http://192.168.99.100:30251/image/post 它会在 / unknown_people 下寻找名为 unknown220.jpg 的图像，在 unknown_folder 中找到与未知图像中的人相对应的图像，并返回匹配图像的名称。 查看日志，你会看到如下内容： 12345678910111213# Receiver❯ curl -d &apos;&#123;&quot;path&quot;:&quot;/unknown_people/unknown219.jpg&quot;&#125;&apos; http://192.168.99.100:30251/image/postgot path: &#123;Path:/unknown_people/unknown219.jpg&#125;image saved with id: 4image sent to nsq# Image Processor2018/03/26 18:11:21 INF 1 [images/ch] querying nsqlookupd http://nsqlookup.default.svc.cluster.local:4161/lookup?topic=images2018/03/26 18:11:59 Got a message: 42018/03/26 18:11:59 Processing image id: 42018/03/26 18:12:00 got person: Hannibal2018/03/26 18:12:00 updating record with person id2018/03/26 18:12:00 done 这样，所有服务就部署完成了。 前端最后，还有一个小型的 web 应用程序，它能够方便地展示数据库中的信息。这也是一个面向公众的接收服务，其参数与接收器相同。 它看起来像这样： 总结我们现在正处于部署一系列服务的阶段。回顾一下我迄今为止使用的命令： 123456kubectl apply -f mysql.yamlkubectl apply -f nsqlookup.yamlkubectl apply -f receiver.yamlkubectl apply -f image_processor.yamlkubectl apply -f face_recognition.yamlkubectl apply -f frontend.yaml 由于应用程序不会在启动时分配连接，因此可以按任意顺序排列。（除了 image_processor 的 NSQ 消费者。） 如果没有错误，使用 kubectl get pods 查询运行 pod 的 kube 应该显示如下： 12345678❯ kubectl get podsNAME READY STATUS RESTARTS AGEface-recog-6bf449c6f-qg5tr 1/1 Running 0 1mimage-processor-deployment-6467468c9d-cvx6m 1/1 Running 0 31smysql-7d667c75f4-bwghw 1/1 Running 0 36snsqd-584954c44c-299dz 1/1 Running 0 26snsqlookup-7f5bdfcb87-jkdl7 1/1 Running 0 11sreceiver-deployment-5cb4797598-sf5ds 1/1 Running 0 26s 运行中的 minikube service list： 12345678910111213❯ minikube service list|-------------|----------------------|-----------------------------|| NAMESPACE | NAME | URL ||-------------|----------------------|-----------------------------|| default | face-recog | No node port || default | kubernetes | No node port || default | mysql | No node port || default | nsqd | No node port || default | nsqlookup | No node port || default | receiver-service | http://192.168.99.100:30251 || kube-system | kube-dns | No node port || kube-system | kubernetes-dashboard | http://192.168.99.100:30000 ||-------------|----------------------|-----------------------------| 滚动更新滚动更新过程中会发生什么？ 正如在软件开发过程中发生的那样，系统的某些部分需要/需要进行更改。那么，如果我改变其中一个组件而不影响其他组件，同时保持向后兼容性而不中断用户体验，我们的集群会发生什么？幸运的是 Kubernetes 可以提供帮助。 我诟病的是 API 一次只能处理一个图像。不幸的是，这里没有批量上传选项。 代码目前，我们有以下处理单个图像的代码段： 1234567891011// PostImage 处理图像的文章。 将其保存到数据库// 并将其发送给 NSQ 以供进一步处理。func PostImage(w http.ResponseWriter, r *http.Request) &#123;...&#125;func main() &#123; router := mux.NewRouter() router.HandleFunc(&quot;/image/post&quot;, PostImage).Methods(&quot;POST&quot;) log.Fatal(http.ListenAndServe(&quot;:8000&quot;, router))&#125; 我们有两种选择：用 / images / post 添加一个新端点，并让客户端使用它，或者修改现有的端点。 新客户端代码的优势在于，如果新端点不可用，它可以退回到提交旧的方式。然而，旧客户端代码没有这个优势，所以我们无法改变我们的代码现在的工作方式。考虑一下：你有90台服务器，并且你做了一个缓慢的滚动更新，在更新的同时一次只取出一台服务器。如果更新持续一分钟左右，整个过程大约需要一个半小时才能完成（不包括任何并行更新）。 在此期间，你的一些服务器将运行新代码，其中一些将运行旧代码。调用是负载均衡的，因此你无法控制哪些服务器会被击中。如果客户试图以新的方式进行调用，但会触及旧服务器，则客户端将失败。客户端可以尝试并回退，但是由于你删除了旧版本，它将不会成功，除非很巧合地命中了运行新代码的服务器，用新代码命中服务器（假设没有设置粘滞会话）。 另外，一旦所有服务器都更新完毕，旧客户端将无法再使用你的服务。 现在，你可以争辩说，你不想永远保留你的代码的旧版本。这在某种意义上是正确的。这就是为什么我们要修改旧代码，只需稍微增加一点就可以调用新代码。这样，一旦所有客户端都被迁移了，代码就可以简单地被删除而不会有任何问题。 新的端点我们来添加一个新的路径方法： 123...router.HandleFunc(&quot;/images/post&quot;, PostImages).Methods(&quot;POST&quot;)... 更新旧版本以调用带有修改后版本的新版本，如下所示： 123456789101112131415161718192021222324// PostImage 处理图像的文章。 将其保存到数据库// 并将其发送给 NSQ 以供进一步处理。func PostImage(w http.ResponseWriter, r *http.Request) &#123; var p Path err := json.NewDecoder(r.Body).Decode(&amp;p) if err != nil &#123; fmt.Fprintf(w, &quot;got error while decoding body: %s&quot;, err) return &#125; fmt.Fprintf(w, &quot;got path: %+v\n&quot;, p) var ps Paths paths := make([]Path, 0) paths = append(paths, p) ps.Paths = paths var pathsJSON bytes.Buffer err = json.NewEncoder(&amp;pathsJSON).Encode(ps) if err != nil &#123; fmt.Fprintf(w, &quot;failed to encode paths: %s&quot;, err) return &#125; r.Body = ioutil.NopCloser(&amp;pathsJSON) r.ContentLength = int64(pathsJSON.Len()) PostImages(w, r)&#125; 那么，命名可能会更好，但你应该得到基本的想法。我正在修改传入的单个路径，将它包装成新的格式并发送给新的端点处理程序。就是这样！ 还有一些修改。要查看它们，请查看此PR：Rolling Update Bulk Image Path PR。 现在，可以通过两种方式调用接收器： 12345# 单个路径:curl -d &apos;&#123;&quot;path&quot;:&quot;unknown4456.jpg&quot;&#125;&apos; http://127.0.0.1:8000/image/post# 多个路径:curl -d &apos;&#123;&quot;paths&quot;:[&#123;&quot;path&quot;:&quot;unknown4456.jpg&quot;&#125;]&#125;&apos; http://127.0.0.1:8000/images/post 在这里，客户端是 curl。通常情况下，如果客户端是个服务，我会改一下，在新的路径抛出 404 时可以再试试老的路径。 为简洁起见，我不修改 NSQ 和其他用来批量图像处理的操作，他们仍然会一个一个接收。这就当作业留给你们来做了。 新的镜像要执行滚动更新，我必须首先从接收器服务创建一个新镜像。 1docker build -t skarlso/kube-receiver-alpine:v1.1 . 一旦完成，我们可以开始推出更改。 滚动更新在 Kubernetes 中，您可以通过多种方式配置滚动更新： 手动更新如果我在我的配置文件中使用了一个名为 v1.0 的容器版本，那么更新只是简单地调用： 1kubectl rolling-update receiver --image:skarlso/kube-receiver-alpine:v1.1 如果在部署期间出现问题，我们总是可以回滚。 1kubectl rolling-update receiver --rollback 它将恢复以前的版本。 不需要大惊小怪，没有任何麻烦。 应用一个新的配置文件手动更新的问题在于它们不在源代码控制中。 考虑一下：由于手动进行“快速修复”，一些服务器得到了更新，但没有人目睹它，并且没有记录。另一个人出现并对模板进行更改并将模板应用到群集。所有服务器都会更新，然后突然出现服务中断。 长话短说，更新后的服务器已经被覆盖，因为该模板没有反映手动完成的工作。 推荐的方法是更改​​模板以使用新版本，并使用 apply 命令应用模板。 Kubernetes 建议使用 ReplicaSets 进行部署应处理分发这意味着滚动更新必须至少有两个副本。如果少于两个副本存在，则更新将不起作用（除非 maxUnavailable 设置为 1）。我增加了 yaml 的副本数量。我还为接收器容器设置了新的镜像版本。 1234567 replicas: 2... spec: containers: - name: receiver image: skarlso/kube-receiver-alpine:v1.1... 看看处理情况，这是你应该看到的： 12❯ kubectl rollout status deployment/receiver-deploymentWaiting for rollout to finish: 1 out of 2 new replicas have been updated... 您可以通过指定模板的 strategy 部分添加其他部署配置设置，如下所示： 12345strategy:type: RollingUpdaterollingUpdate: maxSurge: 1 maxUnavailable: 0 有关滚动更新的更多信息，请参见以下文档：Deployment Rolling Update, Updating a Deployment, Manage Deployments, Rolling Update using ReplicaController。 MINIKUBE 的用户注意：由于我们在具有一个节点和一个应用程序副本的本地机器上执行此操作，我们必须将 maxUnavailable 设置为 1; 否则 Kubernetes 将不允许更新发生，并且新版本将保持 Pending 状态。这是因为我们不允许存在没有运行容器的服务，这基本上意味着服务中断。 Scaling用 Kubernetes 来 scaling 比较容易。由于它正在管理整个集群，因此基本上只需将一个数字放入所需副本的模板中即可使用。 迄今为止这是一篇很棒的文章，但时间太长了。我正在计划编写一个后续行动，我将通过多个节点和副本真正扩展 AWS 的功能; 再加上 Kops 部署 Kubernetes 集群。敬请期待！ 清理12kubectl delete deployments --allkubectl delete services -all 写在最后女士们，先生们。我们用 Kubernetes 编写，部署，更新和扩展了（当然还不是真的）分布式应用程序。 如果您有任何问题，请随时在下面的评论中讨论。我非常乐意解答。 我希望你享受阅读它，虽然这很长， 我正在考虑将它分成多篇博客，但是一个整体的单页指南是有用的，并且可以很容易地找到，保存和打印。 感谢您的阅读。 本文永久链接：https://github.com/xitu/gold-miner/blob/master/TODO1/kubernetes-distributed-application.md 译者：maoqyhz 校对者：cf020031308、HCMY 如果发现译文存在错误或其他需要改进的地方，欢迎到 掘金翻译计划 对译文进行修改并 PR，也可获得相应奖励积分。文章开头的 本文永久链接 即为本文在 GitHub 上的 MarkDown 链接。]]></content>
      <categories>
        <category>翻译计划</category>
      </categories>
      <tags>
        <tag>掘金翻译计划</tag>
        <tag>Virtualization</tag>
        <tag>Kubernetes</tag>
        <tag>Distribution</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git push 时如何避免出现 "Merge branch 'master' of ..."]]></title>
    <url>%2F2018%2F06%2F18%2F%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E5%87%BA%E7%8E%B0%20Merge%20branch%20master%20of%2F</url>
    <content type="text"><![CDATA[在使用 Git 的进行代码版本控制的时候，往往会发现在 log 中出现 “Merge branch ‘master’ of …” 这句话，如下图所示。日志中记录的一般为开发过程中对代码的改动信息，如果出现过多例如上述描述的信息会造成日志的污染。 阅读了一些外文的博客，下面就来一探究竟。 产生原因分析当多人合作开发一个项目时，本地仓库落后于远程仓库是一个非常正常的事情，可参考下图。 123A-B-C(master) \ D(origin/master) 具体情境如下： 我当前拉取的远端版本为 B，此时修改了代码，并在本地仓库 commit 一次，但并未 push 到远端仓库。 另一位开发者在 B 的基础上，同样 commit 了一次并 push 到远端仓库。那么这个时候，我再 push 自己的代码就会发生错误，如下。 1234567To github.com:maoqyhz/usegit.git! [rejected] master -&gt; master (fetch first)error: failed to push some refs to &apos;git@github.com:maoqyhz/usegit.git&apos;hint: Updates were rejected because the remote contains work that you dohint: not have locally. This is usually caused by another repository pushinghint: to the same ref. You may want to first integrate the remote changeshint: (e.g., &apos;git pull ...&apos;) before pushing again. 这个时候我们会选择，先 pull，再 push。Ok，push 成功，但是此时我们查看 log 就会发现除了我们自己提交的那条日志之外，会多出一条 “Merge branch ‘master’ of …”。 那么，为什么会出现这种现象呢？其实是与 Git 的工作原理有关，对 Git 比较了解的人应该会知道，无论是 pull、push 亦或是 merge 操作，其实背后都是有很多的不同的模式的。 在进行 pull 操作的同时，其实就是 fetch+merge 的一个过程。我们从 remote 分支中拉取新的更新，然后再合并到本地分支中去。 如果 remote 分支超前于本地分支，并且本地分支没有任何 commit 的，直接从 remote 进行 pull 操作，默认会采用 fast-forward 模式，这种模式下，并不会产生合并节点，也就是说不会产生多余的那条 log 信息 如果想之前那样，本地先 commit 后再去 pull，那么此时，remote 分支和本地会分支会出现分叉，这个时候使用 pull 操作拉取更新时，就会进行分支合并，产生合并节点和 log 信息。这两种状态分别如下图所示：123456789# fast-forword A-B-D(origin/master) \ C&apos;(master)# mergeA-B-C-E(master) \ / D(origin/master) 如何避免为了去除自动生成的 log 信息，有以下几种解决方案： 如果你使用的是 Git Bash，直接使用 git pull --rebase。如果拉取不产生冲突，会直接 rebase，不会产生分支合并操作，如果有冲突则需要手动 fix 后，自行合并。 如果使用的是 GUI，例如 TortoiseGit，可以先 fetch，再手动 rebase 就可以了。 关于 rebase 和 merge关于什么时候使用 rebase，什么时候使用 merge，开发者总结了几条规则： 从 remote 分支拉取更新到本地时，使用 rebase。 当完成 bug 修复或新功能时，使用 merge 将子分支合并到主分支。 没有人应该 rebase 一根共享的分支。 有关这两者具体的操作，可以参考我在文章最后列出的博客。 References git-merge完全解析 git: Why “Merge branch ‘master’ of … ”? when pull and push 4 Ways to Avoid Merge Commits in Git (or How to Stop Being a Git Tit) Git rebase and the golden rule explained. Git - When to Merge vs. When to Rebase]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[译]通往 Java 函数式编程的捷径]]></title>
    <url>%2F2018%2F06%2F16%2F%E8%AF%91-%E9%80%9A%E5%BE%80Java%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E7%9A%84%E6%8D%B7%E5%BE%84%2F</url>
    <content type="text"><![CDATA[原文地址：An easier path to functional programming in Java 原文作者：Venkat Subramaniam 译文出自：掘金翻译计划 以声明式的思想在你的 Java 程序中使用函数式编程技术Java™ 开发人员习惯于面向命令式和面向对象的编程，因为这些特性自 Java 语言首次发布以来一直受到支持。在 Java 8 中，我们获得了一组新的强大的函数式特性和语法。函数式编程已经存在了数十年，与面向对象编程相比，函数式编程通常更加简洁和达意，不易出错，并且更易于并行化。所以有很好的理由将函数式编程特性引入到 Java 程序中。尽管如此，在使用函数式特性进行编程时，就如何设计你的代码这一点上需要进行一些改变。 关于本文 Java 8 是 Java 语言自诞生以来最重要的更新，它包含如此多的新特性，以至于你可能想知道应该从哪开始了解它。在本系列中，身为作家和教育家的 Venkat Subramaniam 提供了一种符合 Java 语言习惯的 Java 8 学习方式。邀请你进行简短的探索后，重新思考你认为理所当然的 Java 一贯用法和规范，同时逐渐将新技术和语法集成到你的程序中去。 我认为，以声明式的思想而不是命令式的思想来编程，可以更加轻松地向更加函数化的编程风格过渡。在 Java 8 idioms series 这个系列的第一篇文章中，我解释了命令式、声明式和函数式编程风格之间的异同。然后，我将向你展示如何使用声明式的思想逐渐将函数式编程技术集成到你的 Java 程序中。 命令式风格（面向过程）受命令式编程风格训练的开发者习惯于告诉程序需要做什么以及如何去做。这里是一个简单的例子： 清单 1. 以命令式风格编写的 findNemo 方法 12345678910111213141516171819202122232425import java.util.*;public class FindNemo &#123; public static void main(String[] args) &#123; List&lt;String&gt; names = Arrays.asList(&quot;Dory&quot;, &quot;Gill&quot;, &quot;Bruce&quot;, &quot;Nemo&quot;, &quot;Darla&quot;, &quot;Marlin&quot;, &quot;Jacques&quot;); findNemo(names); &#125; public static void findNemo(List&lt;String&gt; names) &#123; boolean found = false; for(String name : names) &#123; if(name.equals(&quot;Nemo&quot;)) &#123; found = true; break; &#125; &#125; if(found) System.out.println(&quot;Found Nemo&quot;); else System.out.println(&quot;Sorry, Nemo not found&quot;); &#125;&#125; 方法 findNemo() 首先初始化一个可变变量 flag，也称为垃圾变量（garbage variable）。开发者经常会给予某些变量一个临时性的名字，例如 f、t、temp 以表明它们根本不应该存在。在本例中，这些变量应该被命名为 found。 接下来，程序会循环遍历给定的 names 列表，每次都会判断当前遍历的值是否和待匹配值相同。在这个例子中，待匹配值为 Nemo，如果遍历到的值匹配，程序会将标志位设为 true，并执行流程控制语句 “break” 跳出循环。 这是对于广大 Java 开发者最熟悉的编程风格 —— 命令式风格的程序，因此你可以定义程序的每一步：你告诉程序遍历每一个元素，和待匹配值进行比较，设置标志位，以及跳出循环。命令式编程风格让你可以完全控制程序，有的时候这是一件好事。但是，换个角度来看，你做了很多机器可以独立完成的工作，这势必导致生产力下降。因此，有的时候，你可以通过少做事来提高生产力。 声明式风格声明式编程意味着你仍然需要告诉程序需要做什么，但是你可以将实现细节留给底层函数库。让我们看看使用声明式编程风格重写清单 1 中的 findNemo 方法时会发生什么： 清单 2. 以声明式风格编写的 findNemo 方法 123456public static void findNemo(List&lt;String&gt; names) &#123; if(names.contains(&quot;Nemo&quot;)) System.out.println(&quot;Found Nemo&quot;); else System.out.println(&quot;Sorry, Nemo not found&quot;);&#125; 首先需要注意的是，此版本中没有任何垃圾变量。你也不需要在遍历集合中浪费精力。相反，你只需要使用内建的 contains() 方法来完成这项工作。你仍然要告诉程序需要做什么，集合中是否包含我们正在寻找的值，但此时你已经将细节交给底层的方法来实现了。 在命令式编程风格的例子中，你控制了遍历的流程，程序可以完全按照指令进行；在声明式的例子中，只要程序能够完成工作，你完全不需要关注它是如何工作的。contains() 方法的实现可能会有所不同，但只要结果符合你的期望，你就会对此感到满意。更少的工作能够得到相同的结果。 训练自己以声明式的编程风格来进行思考将更加轻松地向更加函数化的编程风格过渡。原因在于，函数式编程风格是建立在声明式风格之上的。声明式风格的思维可以让你逐渐从命令式编程转换到函数式编程。 函数式编程风格虽然函数式风格的编程总是声明式的，但是简单地使用声明式风格编程并不等同与函数式编程。这是因为函数式编程时将声明式编程和高阶函数结合在了一起。图 1 显示了命令式，声明式和函数式编程风格之间的关系。 图 1. 命令式、声明式和函数式编程风格之间的关系 Java 中的高阶函数在 Java 中，你可以将对象传递给方法，在方法中创建对象，也可以从方法中返回对象。同时你也可以用函数做相同的事情。也就是说，你可以将函数传递给方法，在方法中创建函数，也可以从方法中返回函数。 在这种情况下，方法是类的一部分（静态或实例），但是函数可以是方法的一部分，并且不能有意地与类或实例相关联。一个可以接收、创建、或者返回函数的方法或函数称之为高阶函数。 一个函数式编程的例子采用新的编程风格需要改变你对程序的看法。这是一个从简单例子的练习开始，到构建更加复杂程序的过程。 清单 3. 命令式编程风格下的 Map 12345678910111213141516171819202122import java.util.*;public class UseMap &#123; public static void main(String[] args) &#123; Map&lt;String, Integer&gt; pageVisits = new HashMap&lt;&gt;(); String page = &quot;https://agiledeveloper.com&quot;; incrementPageVisit(pageVisits, page); incrementPageVisit(pageVisits, page); System.out.println(pageVisits.get(page)); &#125; public static void incrementPageVisit(Map&lt;String, Integer&gt; pageVisits, String page) &#123; if(!pageVisits.containsKey(page)) &#123; pageVisits.put(page, 0); &#125; pageVisits.put(page, pageVisits.get(page) + 1); &#125;&#125; 在清单 3 中，main() 函数创建了一个 HashMap 来保存网站访问次数。同时，incrementPageVisit() 方法增加了每次访问给定页面的计数。我们将聚焦此方法。 以命令式编程风格写的 incrementPageVisit() 方法：它的工作是为给定页面增加一个计数，并存储在 Map 中。该方法不知道给定页面是否已经有计数值，所以会先检查计数值是否存在，如果不存在，会为该页面插入一个值为”0”的计数值。然后再获取该计数值，递增它，并将新的计数值存储在 Map 中。 以声明式的方式思考需要你将方法的设计从 “how” 转变到 “what”。当 incrementPageVisit() 方法被调用时，你需要将给定的页面计数值初始化为 1 或者计数值加 1。这就是 what。 因为你是通过声明式编程的，那么下一步就是在 JDK 库中寻找可以完成这项工作且实现了 Map 接口的方法。换言之，你需要找到一个知道如何完成你指定任务的内建方法。 事实证明 merge() 方法非常适合你的而目的。清单 4 使用新的声明式方法对清单 3 中的 incrementPageVisit() 方法进行修改。但是，在这种情况下，你不仅仅只是选择更智能的方法来写出更具声明性风格的代码，因为 merge() 是一个更高阶的函数。所以说，新的代码实际上是一个体现函数式风格的很好的例子： 清单 4. 函数式编程风格下的 Map 123public static void incrementPageVisit(Map&lt;String, Integer&gt; pageVisits, String page) &#123; pageVisits.merge(page, 1, (oldValue, value) -&gt; oldValue + value); &#125; 在清单 4 中，page 作为第一个参数传递给 merge()：map 中键对应的值将会被更新。第二个参数作为初始值，如果 Map 中不存在指定键的值，那么该值将会赋值给 Map 中键对应的值（在本例中为”1”）。第三个参数为一个 lambda 表达式，接受当前 Map 中键对应的值和该函数中第二个参数对应的值作为参数。lambda 表达式返回其参数的总和，实际上增加了计数值。（编者注：感谢 István Kovács 修正了代码错误） 将清单 4 的 incrementPageVisit() 方法中的单行代码与清单 3 中的多行代码进行比较。虽然清单 4 中的程序是函数式编程风格的一个例子，但通过声明性地思想去思考问题帮助能够我们实现飞跃。 总结在 Java 程序中采用函数式编程技术和语法有很多好处：代码更简洁，更富有表现力，移动部分更少，实现并行化更容易，并且通常比面向对象的代码更易理解。 目前面临的挑战是，如何将你的思维从绝大多数开发人员所熟悉的命令式编程风格转变为以声明式的方式进行思考。 虽然函数式编程并没有那么简单或直接，但是你可以学习专注于你希望程序做什么而不是如何做这件事，来取得巨大的飞跃。通过允许底层函数库管理执行，你将逐渐直观地了解用于构建函数式编程模块的高阶函数。 本文永久链接：https://github.com/xitu/gold-miner/blob/master/TODO1/an-easier-path-to-functional-programming-in-java.md 译者：maoqyhz 校对者：satansk、lihanxiang 如果发现译文存在错误或其他需要改进的地方，欢迎到 掘金翻译计划 对译文进行修改并 PR，也可获得相应奖励积分。文章开头的 本文永久链接 即为本文在 GitHub 上的 MarkDown 链接。]]></content>
      <categories>
        <category>翻译计划</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>掘金翻译计划</tag>
        <tag>Functional Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[译]深度学习中所需的线性代数知识]]></title>
    <url>%2F2018%2F06%2F08%2F%E8%AF%91-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E6%89%80%E9%9C%80%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[原文地址：Linear Algebra for Deep Learning 原文作者：Vihar Kurama 译文出自：掘金翻译计划 每个深度学习项目背后的数学知识。 深度学习是机器学习的一个子领域，涉及一些模仿人脑结构和功能的人工神经网络算法。 线性代数是一种连续的而非离散的数学形式，许多计算机科学家对它几乎没有经验。对于理解和使用许多机器学习算法，特别是深度学习算法，理解线性代数是非常重要的。 为什么是数学？线性代数，概率论和微积分是组成机器学习的三种“语言”。学习这些数学知识将有助于深入理解底层算法机制，并且开发新的算法。 当我们深入到底层时，深度学习背后的一切都是数学。因此在学习深度学习和编程之前，理解基本的线性代数知识是至关重要的。 源码 深度学习背后的核心数据结构是标量，矢量，矩阵和张量。让我们使用这些数据结构，通过编程的方式来解决所有基本的线性代数问题。 标量标量是单个数字，也可以视为 0 阶张量。符号 x∈ℝ 表示 x 是一个标量，属于一组实数值 ℝ。 以下是深度学习中不同数集的表示。ℕ 表示正整数集合 (1,2,3,…)。ℤ 表示结合了正值，负值和零值的整数集合。ℚ 表示有理数集合。 在 Python 中有一些内置的标量类型，int、float、complex、bytes and Unicode。在 Numpy（一个 Python 库）中，有 24 种新的基本数据类型来描述不同类型的标量。有关数据类型的信息，请参阅 文档。 在 Python 中定义标量和相关操作： 下面的代码段解释了一些运算运算符在标量中的应用。 123456789# 内置标量a = 5b = 7.5print(type(a))print(type(b))print(a + b)print(a - b)print(a * b)print(a / b) 123456&lt;class &apos;int&apos;&gt;&lt;class &apos;float&apos;&gt;12.5-2.537.50.6666666666666666 下面的代码段可以检查给出的变量是否为标量。 123456789101112import numpy as np# 判断是否为标量的函数def isscalar(num): if isinstance(num, generic): return True else: return Falseprint(np.isscalar(3.1))print(np.isscalar([3.1]))print(np.isscalar(False)) 123TrueFalseTrue 向量向量是单数的有序数组，是一阶张量的例子。向量是被称为矢量空间的对象的片段。向量空间可以被认为是特定长度（或维度）的所有可能向量的整个集合。用 ℝ^3 表示的三维实值向量空间，通常用于从数学角度表示我们对三维空间的现实世界概念。 为了明确地定位到矢量的某个分量，矢量的第 i 个标量元素被写为 x[i]。 在深度学习中，向量通常代表特征向量，其原始组成部分定义了具体特征的相关性。这些元素可以包括二维图像中一组像素的强度的相关重要性或者各种金融工具的历史价格值。 在 Python 中定义向量和相关操作： 123456789101112131415161718192021import numpy as np# 定义向量x = [1, 2, 3]y = [4, 5, 6]print(type(x))# 这样做不会得到向量和print(x + y)# 使用 Numpy 进行向量相加z = np.add(x, y)print(z)print(type(z))# 向量叉乘mul = np.cross(x, y)print(mul) 12345&lt;class &apos;list&apos;&gt;[1, 2, 3, 4, 5, 6][5 7 9]&lt;class &apos;numpy.ndarray&apos;&gt;[-3 6 -3] 矩阵矩阵是由数字组成的矩形阵列，是 2 阶张量的一个例子。如果 m 和 n 是正整数，即 m，n∈ℕ，则 m×n 矩阵包含 m*n 个数字，m 行 n 列。 完整的 m×n 矩阵可写为： 将全矩阵显示简写为以下表达式通常很有用： 在 Python 中，我们使用 Numpy 库来帮助我们创建 N 维数组。数组基本上可看做矩阵，我们使用矩阵方法，并通过列表来构造一个矩阵。 $python 123456789101112131415161718192021&gt;&gt;&gt; import numpy as np&gt;&gt;&gt; x = np.matrix([[1,2],[2,3]])&gt;&gt;&gt; xmatrix([[1, 2], [2, 3]])&gt;&gt;&gt; a = x.mean(0)&gt;&gt;&gt; amatrix([[1.5, 2.5]])&gt;&gt;&gt; # 对矩阵求均值。（其中 axis 不设置值，对 m*n 个数求均值，返回一个实数；axis = 0：压缩行，对各列求均值，返回 1* n 矩阵；axis =1 ：压缩列，对各行求均值，返回 m *1 矩阵）。&gt;&gt;&gt; z = x.mean(1)&gt;&gt;&gt; zmatrix([[1.5], [2.5]])&gt;&gt;&gt; z.shape(2, 1)&gt;&gt;&gt; y = x - zmatrix([[-0.5, 0.5], [-0.5, 0.5]])&gt;&gt;&gt; print(type(z))&lt;class &apos;numpy.matrixlib.defmatrix.matrix&apos;&gt; 在 Python 中定义矩阵和相关操作： 矩阵加法矩阵可以与标量、向量和其他矩阵进行加法运算。每个操作都有精确的定义。这些技术经常用于机器学习和深度学习，所以值得花时间去熟悉它们。 123456789# 矩阵加法import numpy as npx = np.matrix([[1, 2], [4, 3]])sum = x.sum()print(sum)# Output: 10 矩阵与矩阵相加C = A + B (A 与 B 的维度需要相同 ) shape 方法返回矩阵的维度，add 方法接受两个矩阵参数并返回这两个矩阵的和。如果两个矩阵的维度不一致 add 方法将会抛出一个异常，说无法将其相加。 123456789101112131415161718192021# 矩阵与矩阵相加import numpy as npx = np.matrix([[1, 2], [4, 3]])y = np.matrix([[3, 4], [3, 10]])print(x.shape)# (2, 2)print(y.shape)# (2, 2)m_sum = np.add(x, y)print(m_sum)print(m_sum.shape)&quot;&quot;&quot;Output :[[4 6] [7 13]](2, 2)&quot;&quot;&quot; 矩阵与标量相加将给定的标量添加到给定矩阵中的所有元素。 123456789101112# 矩阵与标量相加import numpy as npx = np.matrix([[1, 2], [4, 3]])s_sum = x + 1print(s_sum)&quot;&quot;&quot;Output:[[2 3] [5 4]]&quot;&quot;&quot; 矩阵与标量的乘法将给定的标量乘以给定矩阵中的所有元素。 1234567891011# 矩阵与标量的乘法import numpy as npx = np.matrix([[1, 2], [4, 3]])s_mul = x * 3print(s_mul)&quot;&quot;&quot;[[3 6] [12 9]]&quot;&quot;&quot; 矩阵乘法维度为（m x n）的矩阵 A 和维度为（n x p）的矩阵 B 相乘，最终得到维度为（m x p）的矩阵 C。 源码 123456789101112# 矩阵乘法import numpy as npa = [[1, 0], [0, 1]]b = [1, 2]np.matmul(a, b)# Output: array([1, 2])complex_mul = np.matmul([2j, 3j], [2j, 3j])print(complex_mul)# Output: (-13+0j) 矩阵转置通过转置，您可以将行向量转换为列向量，反之亦然： A=[a_ij_]mxn AT=[a_ji_]n×m 1234567891011121314151617# 矩阵转置import numpy as npa = np.array([[1, 2], [3, 4]])print(a)&quot;&quot;&quot;[[1 2] [3 4]]&quot;&quot;&quot;a.transpose()print(a)&quot;&quot;&quot;array([[1, 3], [2, 4]])&quot;&quot;&quot; 张量更加泛化的实体 —— 张量，封装了标量、矢量和矩阵。在物理科学和机器学习中，有时需要使用超过两个顺序的张量。 源码 我们使用像 TensorFlow 或 PyTorch 这样的 Python 库来声明张量，而不是使用嵌套矩阵来表示。 在 PyTorch 中定义一个简单的张量： 123456789101112131415161718192021222324import torcha = torch.Tensor([26])print(type(a))# &lt;class &apos;torch.FloatTensor&apos;&gt;print(a.shape)# torch.Size([1])# 创建一个 5*3 的随机 torch 变量。t = torch.Tensor(5, 3)print(t)&quot;&quot;&quot; 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 7.0065e-45 1.1614e-41 0.0000e+00 2.2369e+08 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 nan nan -1.4469e+35[torch.FloatTensor of size 5x3]&quot;&quot;&quot;print(t.shape)# torch.Size([5, 3]) Python 中张量的运算操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import torch# 创建张量p = torch.Tensor(4,4)q = torch.Tensor(4,4)ones = torch.ones(4,4)print(p, q, ones)&quot;&quot;&quot;Output: 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.6009e-19 4.4721e+21 6.2625e+22 4.7428e+30 3.1921e-09 8.0221e+17 5.1019e-08 8.1121e+17 8.1631e-07 8.2022e+17 1.1703e-19 1.5637e-01[torch.FloatTensor of size 4x4] 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.8217e-44 1.1614e-41 0.0000e+00 2.2369e+08 0.0000e+00 0.0000e+00 2.0376e-40 2.0376e-40 nan nan -5.3105e+37 nan[torch.FloatTensor of size 4x4] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1[torch.FloatTensor of size 4x4]&quot;&quot;&quot;print(&quot;Addition:&#123;&#125;&quot;.format(p + q))print(&quot;Subtraction:&#123;&#125;&quot;.format(p - ones))print(&quot;Multiplication:&#123;&#125;&quot;.format(p * ones))print(&quot;Division:&#123;&#125;&quot;.format(q / ones))&quot;&quot;&quot;Addition: 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.6009e-19 4.4721e+21 6.2625e+22 4.7428e+30 3.1921e-09 8.0221e+17 5.1019e-08 8.1121e+17 nan nan -5.3105e+37 nan[torch.FloatTensor of size 4x4]Subtraction:-1.0000e+00 -1.0000e+00 -1.0000e+00 -1.0000e+00-1.0000e+00 4.4721e+21 6.2625e+22 4.7428e+30-1.0000e+00 8.0221e+17 -1.0000e+00 8.1121e+17-1.0000e+00 8.2022e+17 -1.0000e+00 -8.4363e-01[torch.FloatTensor of size 4x4]Multiplication: 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.6009e-19 4.4721e+21 6.2625e+22 4.7428e+30 3.1921e-09 8.0221e+17 5.1019e-08 8.1121e+17 8.1631e-07 8.2022e+17 1.1703e-19 1.5637e-01[torch.FloatTensor of size 4x4]Division: 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.8217e-44 1.1614e-41 0.0000e+00 2.2369e+08 0.0000e+00 0.0000e+00 2.0376e-40 2.0376e-40 nan nan -5.3105e+37 nan[torch.FloatTensor of size 4x4]&quot;&quot;&quot; 有关张量和 PyTorch 的更多文档点击这里。 重要的链接 在 Python 中入门深度学习： Deep Learning with Python: The human brain imitation. Introduction To Machine Learning: Machine Learning is an idea to learn from examples and experience, without being explicitly programmed. Instead of… 结束语感谢阅读。如果你发现这个故事很有用，请点击下面的 👏 来传播爱心。 特别鸣谢 Samhita Alla 对本文的贡献。 本文永久链接：https://github.com/xitu/gold-miner/blob/master/TODO1/linear-algebra-for-deep-learning.md 译者：maoqyhz 校对者：kezhenxu94、luochen1992 如果发现译文存在错误或其他需要改进的地方，欢迎到 掘金翻译计划 对译文进行修改并 PR，也可获得相应奖励积分。文章开头的 本文永久链接 即为本文在 GitHub 上的 MarkDown 链接。]]></content>
      <categories>
        <category>翻译计划</category>
      </categories>
      <tags>
        <tag>掘金翻译计划</tag>
        <tag>Deep Learning</tag>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android 恶意样本数据集汇总]]></title>
    <url>%2F2018%2F06%2F01%2FAndroid%E6%81%B6%E6%84%8F%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE%E9%9B%86%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[硕士论文的研究方向为Android恶意应用分类，因此花了一点时间去搜集Android恶意样本。其中一部分来自过去论文的公开数据集，一部分来自社区或平台的样本。现做一个汇总，标明了样本或数据集的采集时间、样本数量、对于论文以及获取方式。 List some android malware datasets in academic research.Some of them are still up to date. 我这里有Drebin的数据集，以及VirusTotal（2018.3）的android恶意样本，约15GB。VirusTotal的数据集在Google云盘上,Drebin数据集我上传了2560个到OneDrive（由于空间受限）。需要的可联系我本人（分享Google云盘需要提供你的gmail）。 历史的数据集例如Drebin、Genome 等可以联系导师，然后发邮件联系他们获取，一些不再共享的也可以联系一些已经拥有数据集的大学和机构，基本上国内知名的大学都会有这些数据集。 VirusTotal的样本可以自己去申请。分为API和恶意文件夹。前者可以等到详细的样本检测报告，后者的话主要是大量的恶意样本。但是VirusTotal样本申请需要填写大量的信息，例如身份、研究的内容、学校和导师的资料等。 Contagio样本的密码，直接联系博主本人即可。 所有样本仅可用于学术研究，并且请指出样本来源。 VirusTotal Mobile Apps Samples VirusTotal: Analyze suspicious files and URLs to detect types of malware including viruses, worms, and trojans. Description: VirusTotal can also be used through a smartphone app. VirusTotal is about empowering the Community in order to build tools that will make the Internet a safer place, as such, we like to credit and feature Community-developed goodies that help the antivirus industry in receiving more files in order to have more visibility into threats. Below you can find links to apps that will allow you to interact with VirusTotal making use of your smartphone, note that these are not developed by VirusTotal itself and so we are not responsible for them. Sample Volume: N/A Collected Time: up to date HomePage: https://www.virustotal.com Way to get: If you need a small volume of sample, login to VirusTotal and download manually. If you need a large volume of sample, email to virusTotal for academic requests. You can choose “access to the Academic API” or “access to a folder of malware” Contagio Mobile Malware Mini DumpDescription: aka “take a sample, leave a sample”Contagio mobile mini-dump is a part of contagiodump.blogspot.com. Contagio mobile mini-dump offers an upload dropbox for you to share your mobile malware samples. You can also download any samples individually or in one zip. Sample Volume: N/A Collected Time: up to date HomePage: http://contagiominidump.blogspot.hk/ Way to get: free for download in Contagio blogs.And you can also download the sample from this link: http://contagiomobile.deependresearch.org/index.html However, the package need password to decompress, you need to email bloger to get password. KoodousDescription: Koodous is a collaborative platform that combines the power of online analysis tools with social interactions between the analysts over a vast APKs repository. Sample Volume: N/A Collected Time: up to date HomePage: https://koodous.com/ Way to get: register and download manually or use the api. The Drebin DatasetDescription: The dataset contains 5,560 applications from 179 different malware families. The samples have been collected in the period of August 2010 to October 2012 and were made available to us by the MobileSandbox project. Sample Volume: 5,560 applications from 179 different malware families Collected Time: 2010.8 - 2012.10 Papers: Daniel Arp, Michael Spreitzenbarth, Malte Huebner, Hugo Gascon, and Konrad Rieck “Drebin: Efficient and Explainable Detection of Android Malware in Your Pocket”, 21th Annual Network and Distributed System Security Symposium (NDSS), February 2014 Michael Spreitzenbarth, Florian Echtler, Thomas Schreck, Felix C. Freling, Johannes Hoffmann, “MobileSandbox: Looking Deeper into Android Applications”, 28th International ACM Symposium on Applied Computing (SAC), March 2013 HomePage: https://www.sec.cs.tu-bs.de/~danarp/drebin/index.html Way to get: send email Android Malware Genome Project (2015/12/21) Due to limited resources and the situation that students involving in this project have graduated, we decide to stop the efforts of malware dataset sharing. Description: In this project, we focus on the Android platform and aim to systematize or characterize existing Android malware. Particularly, with more than one year effort, we have managed to collect more than 1,200 malware samples that cover the majority of existing Android malware families, ranging from their debut in August 2010 to recent ones in October 2011. Sample Volume: more than 1,200 Collected Time: 2010.8 - 2011.10 Papers: Yajin Zhou, Xuxian Jiang, Dissecting Android Malware: Characterization and Evolution. Proceedings of the 33rd IEEE Symposium on Security and Privacy (Oakland 2012). San Francisco, CA, May 2012 HomePage: http://www.malgenomeproject.org/ Way to get: ask someone who had already get this dataset. following universities, research labs and companies Kharon Malware DatasetDescription: The Kharon dataset is a collection of malware totally reversed and documented. This dataset has been constructed to help us to evaluate our research experiments. Its construction has required a huge amount of work to understand the malicous code, trigger it and then construct the documentation. This dataset is now available for research purpose, we hope it will help you to lead your own experiments. Papers: CIDRE, EPI. Kharon dataset: Android malware under a microscope. Learning from Authoritative Security Experiment Results (2016): 1. Homepage: http://kharon.gforge.inria.fr/dataset/ AMD ProjectDescription: AMD contains 24,553 samples, categorized in 135 varieties among 71 malware families ranging from 2010 to 2016. The dataset provides an up-to-date picture of the current landscape of Android malware, and is publicly shared with the community. Sample Volume: 24,553 samples Collected Time: 2010 to 2016 PapersLi Y, Jang J, Hu X, et al. Android malware clustering through malicious payload mining[C]//International Symposium on Research in Attacks, Intrusions, and Defenses. Springer, Cham, 2017: 192-214. Wei F, Li Y, Roy S, et al. Deep Ground Truth Analysis of Current Android Malware[C]//International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment. Springer, Cham, 2017: 252-276. Homepage: http://amd.arguslab.org 更多有关于Android恶意分类的资料，可访问我的github。项目地址为：DroidCC，里面包含了Android恶意检测的工具、最近的参考文献、第三方应用市场等资料。]]></content>
      <categories>
        <category>技术杂记</category>
      </categories>
      <tags>
        <tag>Android Malware</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[『风物长宜放眼量』——序]]></title>
    <url>%2F2018%2F05%2F31%2F%E3%80%8E%E9%A3%8E%E7%89%A9%E9%95%BF%E5%AE%9C%E6%94%BE%E7%9C%BC%E9%87%8F%E3%80%8F%E2%80%94%E2%80%94%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[为个人博客作个序。 3年6个月从博客园搬到了自己搭建的个人博客，日子说长不长，说短也不算短。记得当年刚读本科，什么都不会，刷了一年杭电OJ的水题，就开始跟着老师做起项目来了。当时就有一个同学，无论上课还是下课，都捏着不放，一直都在浏览技术博客，学的技术永远超前过我们所有人，毕业那会已经是CSDN的博客专家了。深谙出名要趁早之道的他，可以说是年少得志，心高气傲，却也的确有这个资本。除了老师，我觉得本科四年，最应该感谢的就是这位了吧，区长。技术上的问题，他能够给出解决方案的同时，亦会有自己的真知灼见，每每去请教问题，也总能得到自己想要的答案。 在坚持写技术博客这件事情上，也是跟他学习的。三年半的时间里，虽然自己的成就远不如区长，但是也一直坚持下来了，从一开始的读书笔记、小水文，到现在也能写出几篇相对有质量的博客（说不上质量高，也总算对他人有一定帮助）。对于技术的passion虽不及区长，但亦有自己的理想。写出一篇博客，即是对自己的知识掌握的肯定，又能够帮助广大的开发者，绝对是一件非常有意义的事情。收获的鲜花和掌声，能够让自己更好的进行下去。现在我又再次效仿区长，开了个个人博客，在写一些技术博客之余，也会写一些其他的见解。 人是思想的芦苇，写技术博客所展现的就是对技术的一种思考，并没有太多的功利性，借用毛主席的一句诗——风物长宜放眼量，博观而约取，厚积而薄发。 To be continued. 在最后奉上区老师的博客地址：fucknmb.com]]></content>
      <categories>
        <category>思考感悟</category>
      </categories>
      <tags>
        <tag>序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo 博客搭建以及 Next 主题美化的经验之谈]]></title>
    <url>%2F2018%2F05%2F19%2FHexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E4%BB%A5%E5%8F%8ANext%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96%E7%9A%84%E7%BB%8F%E9%AA%8C%E4%B9%8B%E8%B0%88%2F</url>
    <content type="text"><![CDATA[这并不是一篇博客搭建教程。内容主要包含个人对于Hexo博客搭建的心得，Next6.0主题美化的部分建议，以及摘录一些各种用于博客搭建的link。 惯例，第一篇博客献给Hexo。 个人博客的搭建不外乎两种，类似Wordpress的动态博客，类似Hexo的静态博客。前者搭建好了之后维护起来还是比较方便的，不管是发文还是添加分类等等都可以在后台管理中进行；而后者则需要手动进行管理，从博客的美化到内容的维护，当然也存在hexo-admin这类的插件。However，前者需要一个服务器，emmm，后者的话托管在github或者coding就ok，短时间内能用完100M的估计也是人才了。 Absolutely，博主选择了后者。Hexo的教程网上多了去了，也写的够详尽够简单了，毕竟Hexo本来也就是一个快速的blog搭建工具，因此也就不再写完整教程了。下面我会写一些针对于当前版本的Hexo以及最受欢迎的主题Next的一些tips，主要内容如下： 搭建一个Hexo&amp;Next的最小博客系统 Next主题美化心得 域名绑定 关于博客图片 备份维护的Tips 搭建一个Hexo&amp;Next的最小博客系统论最小系统的重要性。对于任何一个需要搭建的系统，无论是博客还是论坛，我都推荐新手先根据教程搭建一个最小系统。最小系统顾名思义，就是一个满足需求的最小化的系统。举个栗子，比如你需要搭建Wordpress，这个时候我们就可以先搭建一个最基本的Wordpress博客，即可以进行内容的发布和管理，然后再根据自己的需求去进行主题的美化和插件安装等等，这样操作会更具有条理性。完全没有必要第一次就期望能够顺利搭建完成，直接用于实际生产应用环境。 再看Hexo，Hexo搭建的过程就是单纯的配置文件形式和命令行。有些教程写的非常长，从安装环境、本地部署、美化、第三方插件写到域名、SEO优化等等。内容太多，太复杂，这对于新手就显得不那么友好了。因此在这里，我仅仅描述了如何搭建一个Hexo&amp;Next的最小博客系统，不夹杂其余一些美化优化等操作，待大家玩熟了之后，再进行一些高级的配置。最小博客系统的搭建分为以下几个步骤： 本地环境搭建（Git、Node.js） Github创建博客仓库，初始化GitHub Pages 本地搭建Hexo博客 部署到GitHub Pages . 主题美化 Attention： 这里未包含域名绑定的过程，因为无论GitHub Pages还是Coding Pages，都可以通过用户名自带的域名访问，如果购买了域名的，可参考附录进行域名绑定。 1-4步具体的过程可参考GitHub Pages + Hexo搭建博客，按照这篇博客的步骤走，基本上几分钟时间就可以搭建一个默认主题的Hexo博客了。 默认的主题并不是那么好看，这里我们选择目前最流行的Hexo Next主题，该主题非常简洁，并且有非常详细的配置文档，对于不愿意花大时间在博客美化上的人来说，是极好的。 主题应用具体可参考Next官方文档，我们需要根据文档配置一下信息： Scheme 语言 菜单，包括标签、分类、关于等 作者昵称和站点描述 经过以上几个步骤的配置，一个基本的个人博客就已经成型了，可以在上面进行内容的发布，这也就是上面所提到的一个最小系统。 Next主题美化心得搭建完最小系统的Hexo博客，其实已经可以正常工作了。但是Next主题给了我们更多DIY的空间，根据官方配置文档，我们还能配置例如评论、统计分析、搜索等其他一系列的功能。大家可以根据自己的喜好进行配置。 但是，需要提出的就是，Hexo本身主打的是轻量级博客系统，过多的美化可能会导致博客的卡顿。因此，我只推荐以下个性化设置： Github banner在Next6.0之后，配置自带github_banner，只需要在后面添加自己的github地址即可，例如： 1github_banner: https://github.com/maoqyhz || Follow me on GitHub 博文置顶 评论系统和单篇文章统计这里把这两部分何在一起，主要他们都用到了LeanCloud服务。LeanCloud是一个后端服务商，我们在上面注册后，就可以免费使用其统计和评论的服务。当然，据说leancloud_visitors有一个安全问题，对此比较敏感的可通过Leancloud访客统计插件重大安全漏洞修复指南进行手动修复，也可忽略。 全站统计 开启本地搜索 博客字数统计和阅读所需时间旧版的next主题使用的是hexo-wordcount插件，新版已替换成hexo-symbols-count-time 上述的美化配置，均可在Next官方文档和hexo的next主题个性化教程:打造炫酷网站中找到。 域名绑定github page自带二级域名，同时也支持绑定个人域名。 域名其实分为注册和绑定两部分。 第一，需要去域名服务商哪里购买域名，国内：万网、Dnspod；国外选择余地就更大了，具体的价格可参考www.domcomp.com。博主是在namesilo里买的，价格相对比较便宜。 第二，域名绑定。如果是像博主这样在国外服务商买的域名，一般就不使用其域名解析服务（NS）了，可以换成国内的Dnspod。然后设置别名即可，不需要添加A记录。 具体操作如下： 更换域名服务商的NS，以namesilo为例。 在Dnspod中添加域名和记录。 在博客源文件source/目录下创建一个无文件类型的文件CNAME，并添加自己的域名，例如furur.xyz。更新部署到github上。 由于NS修改需要时间，过一段时间可以刷新下网页看看。 关于博客图片Hexo博客搭建完后，大多会选择部署到Github Pages或者Coding Pages上去，这时候由于空间问题，大家可能会对于博客中的图片放哪的问题存在困惑。网上大多数的人都推荐使用各种图床或者云服务（七牛云）。但是个人觉得如果不是嫌图片加载的速度过慢，其实直接上传图片到github就可以了。Github Pages每人的空间有100M，毕竟技术博客中包含的图片有限，实在有大图，可以先进行在线压缩。一般一篇博客1M都不到，待有恒心写满100篇博客在说吧。上传图片，需要将Hexo配置文件中的post_asset_folder设为true，然后在博客创建时，会在source文件夹下创建于博客同名的文件夹。在里面放图片，博客中直接引用文件名即可。 备份维护的TipsHexo博客需要本地静态部署后，push到服务器上去。善于思考的，应该会想到如果换电脑了，应该如何继续写博客部署到服务器上去呢？具体可参考使用hexo，如果换了电脑怎么更新博客？ 其实原理很简单，知乎中提到的这么多方法，无非就是将除了部署生成的文件之外，其余的文件夹以及配置文件都单独保存好即可。保存的方法自然有很多，可以新建一个源代码分支，也可单独用云服务进行备份。 总结对于coding相关的人来说，Hexo的搭建可以说是非常简单了，加上网上资料丰富，大家可以随意折腾~~~ 附录教程列表 GitHub Pages + Hexo搭建博客 Hexo搭建博客教程 Hexo+GithubPages&amp;CodingPages搭建自己的个人博客 备份维护 使用hexo，如果换了电脑怎么更新博客？ 主题美化 hexo的next主题个性化教程:打造炫酷网站 为NexT主题添加文章阅读量统计功能 Hexo博客添加文章置顶功能 插件 hexo-git-backup hexo-admin]]></content>
      <categories>
        <category>技术杂记</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>hexo-next</tag>
      </tags>
  </entry>
</search>
